{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# üöÄ Valida√ß√£o de Performance - CQR_LightGBM\n",
    "\n",
    "**Objetivo**: Validar a performance do modelo em dados de teste e backtest hist√≥rico\n",
    "\n",
    "**Escopo**: \n",
    "- ‚úÖ M√©tricas de Cross-Validation\n",
    "- ‚úÖ Valida√ß√£o Hist√≥rica (Framework 02c)\n",
    "- ‚úÖ Compara√ß√£o com Baseline\n",
    "- ‚úÖ Aprova√ß√£o para Produ√ß√£o\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ Imports essenciais\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configura√ß√£o visual\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(\"‚úÖ Bibliotecas carregadas\")\n",
    "print(f\"üìÖ Valida√ß√£o executada em: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## üìÇ 1. Carregamento dos Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìÅ Definir caminhos\n",
    "PROJECT_ROOT = Path().absolute().parent if Path().absolute().name == 'notebooks' else Path().absolute()\n",
    "MODELS_DIR = PROJECT_ROOT / 'data' / 'processed' / 'preds'\n",
    "\n",
    "print(f\"üóÇÔ∏è  Diret√≥rio do projeto: {PROJECT_ROOT}\")\n",
    "print(f\"ü§ñ Diret√≥rio dos modelos: {MODELS_DIR}\")\n",
    "\n",
    "# Carregar resultados principais\n",
    "results_files = {\n",
    "    'cv_metrics': MODELS_DIR / 'cv_metrics.json',\n",
    "    'historical_backtest': MODELS_DIR / 'historical_backtest_results.json',\n",
    "    'training_summary': MODELS_DIR / 'training_summary.json'\n",
    "}\n",
    "\n",
    "print(\"\\nüìä Carregando resultados:\")\n",
    "data = {}\n",
    "for key, file_path in results_files.items():\n",
    "    if file_path.exists():\n",
    "        with open(file_path, 'r') as f:\n",
    "            data[key] = json.load(f)\n",
    "        print(f\"‚úÖ {key}: {file_path.name}\")\n",
    "    else:\n",
    "        print(f\"‚ùå {key}: {file_path.name} n√£o encontrado\")\n",
    "        data[key] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## üìà 2. M√©tricas de Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Analisar m√©tricas de CV\n",
    "if data['cv_metrics']:\n",
    "    cv_data = data['cv_metrics']\n",
    "    \n",
    "    print(\"üìà M√âTRICAS DE CROSS-VALIDATION\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Extrair m√©tricas por horizonte\n",
    "    horizons = [42, 48, 54, 60]\n",
    "    cv_summary = {}\n",
    "    \n",
    "    for horizon in horizons:\n",
    "        cv_file = MODELS_DIR / f'cv_metrics_T{horizon}.json'\n",
    "        if cv_file.exists():\n",
    "            with open(cv_file, 'r') as f:\n",
    "                cv_horizon_data = json.load(f)\n",
    "            \n",
    "            if 'mean_metrics' in cv_horizon_data:\n",
    "                metrics = cv_horizon_data['mean_metrics']\n",
    "                cv_summary[horizon] = metrics\n",
    "                \n",
    "                print(f\"\\nüéØ Horizonte {horizon}H:\")\n",
    "                print(f\"   üìâ MAE: {metrics.get('MAE', 'N/A'):.4f}\")\n",
    "                print(f\"   üìä RMSE: {metrics.get('RMSE', 'N/A'):.4f}\")\n",
    "                print(f\"   üéØ Coverage 90%: {metrics.get('Coverage_90', 'N/A'):.3f}\")\n",
    "                \n",
    "                # Verificar se coverage est√° no range aceit√°vel (87% - 93%)\n",
    "                coverage = metrics.get('Coverage_90', 0)\n",
    "                if 0.87 <= coverage <= 0.93:\n",
    "                    print(f\"   ‚úÖ Coverage: OK (target: 90% ¬± 3%)\")\n",
    "                else:\n",
    "                    print(f\"   ‚ö†Ô∏è Coverage: ATEN√á√ÉO (fora do range 87%-93%)\")\n",
    "    \n",
    "    # Visualizar m√©tricas CV\n",
    "    if cv_summary:\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        \n",
    "        horizons_list = list(cv_summary.keys())\n",
    "        mae_values = [cv_summary[h].get('MAE', 0) for h in horizons_list]\n",
    "        rmse_values = [cv_summary[h].get('RMSE', 0) for h in horizons_list]\n",
    "        coverage_values = [cv_summary[h].get('Coverage_90', 0) for h in horizons_list]\n",
    "        \n",
    "        # MAE por horizonte\n",
    "        axes[0].bar(horizons_list, mae_values, color='lightcoral', alpha=0.7)\n",
    "        axes[0].set_title('MAE por Horizonte', fontweight='bold')\n",
    "        axes[0].set_xlabel('Horizonte (H)')\n",
    "        axes[0].set_ylabel('MAE')\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # RMSE por horizonte\n",
    "        axes[1].bar(horizons_list, rmse_values, color='lightblue', alpha=0.7)\n",
    "        axes[1].set_title('RMSE por Horizonte', fontweight='bold')\n",
    "        axes[1].set_xlabel('Horizonte (H)')\n",
    "        axes[1].set_ylabel('RMSE')\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Coverage por horizonte\n",
    "        bars = axes[2].bar(horizons_list, coverage_values, color='lightgreen', alpha=0.7)\n",
    "        axes[2].axhline(y=0.90, color='red', linestyle='--', alpha=0.8, label='Target (90%)')\n",
    "        axes[2].axhline(y=0.87, color='orange', linestyle=':', alpha=0.6, label='Min (87%)')\n",
    "        axes[2].axhline(y=0.93, color='orange', linestyle=':', alpha=0.6, label='Max (93%)')\n",
    "        axes[2].set_title('Coverage 90% por Horizonte', fontweight='bold')\n",
    "        axes[2].set_xlabel('Horizonte (H)')\n",
    "        axes[2].set_ylabel('Coverage')\n",
    "        axes[2].set_ylim(0.80, 1.0)\n",
    "        axes[2].legend()\n",
    "        axes[2].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.suptitle('üìä M√©tricas de Cross-Validation - CQR_LightGBM', fontsize=16, fontweight='bold', y=1.02)\n",
    "        plt.show()\n",
    "        \n",
    "        # Resumo estat√≠stico\n",
    "        avg_mae = np.mean(mae_values)\n",
    "        avg_coverage = np.mean(coverage_values)\n",
    "        coverage_in_range = sum(1 for c in coverage_values if 0.87 <= c <= 0.93)\n",
    "        \n",
    "        print(f\"\\nüìã RESUMO CV:\")\n",
    "        print(f\"üìâ MAE M√©dio: {avg_mae:.4f}\")\n",
    "        print(f\"üéØ Coverage M√©dio: {avg_coverage:.3f}\")\n",
    "        print(f\"‚úÖ Horizontes com coverage OK: {coverage_in_range}/{len(horizons_list)}\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Dados de CV n√£o dispon√≠veis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## üî¨ 3. Valida√ß√£o Hist√≥rica (Framework 02c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéØ Analisar resultados do backtest hist√≥rico\n",
    "if data['historical_backtest']:\n",
    "    backtest_data = data['historical_backtest']\n",
    "    \n",
    "    print(\"üî¨ VALIDA√á√ÉO HIST√ìRICA (FRAMEWORK 02C)\")\n",
    "    print(\"=\" * 55)\n",
    "    \n",
    "    # Informa√ß√µes do framework\n",
    "    config = backtest_data.get('config', {})\n",
    "    gates_summary = backtest_data.get('gates_summary', {})\n",
    "    \n",
    "    print(f\"üìÖ Timestamp: {backtest_data.get('timestamp', 'N/A')}\")\n",
    "    print(f\"üèóÔ∏è Framework: {backtest_data.get('framework_version', 'N/A')}\")\n",
    "    print(f\"‚úÖ Status: {backtest_data.get('validation_status', 'N/A')}\")\n",
    "    \n",
    "    # Configura√ß√£o dos gates\n",
    "    if 'gates' in config:\n",
    "        gates_config = config['gates']\n",
    "        print(f\"\\nüéõÔ∏è CONFIGURA√á√ÉO DOS GATES:\")\n",
    "        print(f\"   üìä Coverage: {gates_config.get('coverage_min', 'N/A')} - {gates_config.get('coverage_max', 'N/A')}\")\n",
    "        print(f\"   üîÑ Crossing rate: < {gates_config.get('crossing_rate_max', 'N/A')}\")\n",
    "        print(f\"   üìà PSI: < {gates_config.get('psi_max', 'N/A')}\")\n",
    "        print(f\"   üìä KS p-value: > {gates_config.get('ks_pvalue_min', 'N/A')}\")\n",
    "    \n",
    "    # Resultados por modelo\n",
    "    print(f\"\\nü§ñ RESULTADOS POR MODELO:\")\n",
    "    for model_name, results in gates_summary.items():\n",
    "        total_passed = results.get('total_passed', 0)\n",
    "        total_gates = results.get('total_gates', 0)\n",
    "        approval_rate = results.get('approval_rate', 0)\n",
    "        decision = results.get('final_decision', 'N/A')\n",
    "        \n",
    "        status_icon = \"‚úÖ\" if decision == \"GO\" else \"‚ùå\"\n",
    "        \n",
    "        print(f\"\\n{status_icon} {model_name}:\")\n",
    "        print(f\"   üéØ Gates aprovados: {total_passed}/{total_gates}\")\n",
    "        print(f\"   üìä Taxa de aprova√ß√£o: {approval_rate:.1%}\")\n",
    "        print(f\"   üèÅ Decis√£o final: {decision}\")\n",
    "    \n",
    "    # Visualizar resultados de aprova√ß√£o\n",
    "    if gates_summary:\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "        \n",
    "        # Gr√°fico de aprova√ß√£o por modelo\n",
    "        models = list(gates_summary.keys())\n",
    "        approval_rates = [gates_summary[m]['approval_rate'] * 100 for m in models]\n",
    "        colors = ['green' if gates_summary[m]['final_decision'] == 'GO' else 'red' for m in models]\n",
    "        \n",
    "        bars1 = ax1.bar(models, approval_rates, color=colors, alpha=0.7)\n",
    "        ax1.set_title('Taxa de Aprova√ß√£o - Sistema 12-Gates', fontweight='bold')\n",
    "        ax1.set_ylabel('Taxa de Aprova√ß√£o (%)')\n",
    "        ax1.set_ylim(0, 105)\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Adicionar valores nas barras\n",
    "        for bar, rate in zip(bars1, approval_rates):\n",
    "            height = bar.get_height()\n",
    "            ax1.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                    f'{rate:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "        \n",
    "        # Gr√°fico de gates aprovados\n",
    "        gates_passed = [gates_summary[m]['total_passed'] for m in models]\n",
    "        gates_total = [gates_summary[m]['total_gates'] for m in models]\n",
    "        \n",
    "        x_pos = np.arange(len(models))\n",
    "        bars2 = ax2.bar(x_pos, gates_passed, color=colors, alpha=0.7, label='Aprovados')\n",
    "        ax2.bar(x_pos, [t - p for t, p in zip(gates_total, gates_passed)], \n",
    "               bottom=gates_passed, color='lightgray', alpha=0.5, label='Reprovados')\n",
    "        \n",
    "        ax2.set_title('Gates Aprovados vs Total', fontweight='bold')\n",
    "        ax2.set_ylabel('N√∫mero de Gates')\n",
    "        ax2.set_xticks(x_pos)\n",
    "        ax2.set_xticklabels(models)\n",
    "        ax2.legend()\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Adicionar valores nas barras\n",
    "        for i, (passed, total) in enumerate(zip(gates_passed, gates_total)):\n",
    "            ax2.text(i, passed/2, str(passed), ha='center', va='center', fontweight='bold')\n",
    "            if total - passed > 0:\n",
    "                ax2.text(i, passed + (total-passed)/2, str(total-passed), ha='center', va='center')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.suptitle('üéØ Resultados da Valida√ß√£o Hist√≥rica', fontsize=16, fontweight='bold', y=1.02)\n",
    "        plt.show()\n",
    "        \n",
    "        # Verificar se CQR_LightGBM foi aprovado\n",
    "        cqr_approved = gates_summary.get('CQR_LightGBM', {}).get('final_decision') == 'GO'\n",
    "        print(f\"\\nüéØ RESULTADO FINAL:\")\n",
    "        if cqr_approved:\n",
    "            print(f\"‚úÖ CQR_LightGBM: APROVADO para produ√ß√£o\")\n",
    "            print(f\"üöÄ Modelo passou em {gates_summary.get('CQR_LightGBM', {}).get('approval_rate', 0):.1%} dos testes\")\n",
    "        else:\n",
    "            print(f\"‚ùå CQR_LightGBM: N√ÉO APROVADO\")\n",
    "            print(f\"‚ö†Ô∏è Necess√°ria revis√£o antes da produ√ß√£o\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Dados de backtest hist√≥rico n√£o dispon√≠veis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## ‚öñÔ∏è 4. Compara√ß√£o com Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Comparar com baseline (se dispon√≠vel)\n",
    "if data['historical_backtest'] and 'fold_results' in data['historical_backtest']:\n",
    "    fold_results = data['historical_backtest']['fold_results']\n",
    "    \n",
    "    print(\"‚öñÔ∏è COMPARA√á√ÉO COM BASELINE\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Extrair m√©tricas dos modelos\n",
    "    model_performance = {}\n",
    "    \n",
    "    for fold in fold_results:\n",
    "        for model_name, model_data in fold['models'].items():\n",
    "            if model_name not in model_performance:\n",
    "                model_performance[model_name] = {'MAE': [], 'Coverage': []}\n",
    "            \n",
    "            # Calcular m√©tricas m√©dias por fold\n",
    "            mae_values = []\n",
    "            coverage_values = []\n",
    "            \n",
    "            for horizon, metrics in model_data['metrics'].items():\n",
    "                mae_values.append(metrics.get('MAE', 0))\n",
    "                coverage_values.append(metrics.get('Coverage_90', 0))\n",
    "            \n",
    "            if mae_values:\n",
    "                model_performance[model_name]['MAE'].append(np.mean(mae_values))\n",
    "            if coverage_values:\n",
    "                model_performance[model_name]['Coverage'].append(np.mean(coverage_values))\n",
    "    \n",
    "    # Calcular estat√≠sticas finais\n",
    "    comparison_results = {}\n",
    "    for model_name, perf in model_performance.items():\n",
    "        comparison_results[model_name] = {\n",
    "            'avg_mae': np.mean(perf['MAE']) if perf['MAE'] else 0,\n",
    "            'avg_coverage': np.mean(perf['Coverage']) if perf['Coverage'] else 0,\n",
    "            'std_mae': np.std(perf['MAE']) if perf['MAE'] else 0\n",
    "        }\n",
    "    \n",
    "    # Display compara√ß√£o\n",
    "    print(f\"\\nüìä M√âTRICAS COMPARATIVAS:\")\n",
    "    for model_name, results in comparison_results.items():\n",
    "        print(f\"\\nü§ñ {model_name}:\")\n",
    "        print(f\"   üìâ MAE M√©dio: {results['avg_mae']:.4f} (¬±{results['std_mae']:.4f})\")\n",
    "        print(f\"   üéØ Coverage M√©dio: {results['avg_coverage']:.3f}\")\n",
    "    \n",
    "    # Calcular melhoria se tivermos CQR_LightGBM e baseline\n",
    "    if 'CQR_LightGBM' in comparison_results and 'HAR-RV_Baseline' in comparison_results:\n",
    "        cqr_mae = comparison_results['CQR_LightGBM']['avg_mae']\n",
    "        baseline_mae = comparison_results['HAR-RV_Baseline']['avg_mae']\n",
    "        \n",
    "        if baseline_mae > 0:\n",
    "            improvement = ((baseline_mae - cqr_mae) / baseline_mae) * 100\n",
    "            \n",
    "            print(f\"\\nüöÄ MELHORIA DO CQR_LightGBM:\")\n",
    "            print(f\"üìà Redu√ß√£o no MAE: {improvement:.1f}%\")\n",
    "            print(f\"üìä MAE Baseline: {baseline_mae:.4f}\")\n",
    "            print(f\"üìä MAE CQR: {cqr_mae:.4f}\")\n",
    "            \n",
    "            if improvement > 20:\n",
    "                print(f\"‚úÖ Melhoria significativa (>{20}%)\")\n",
    "            elif improvement > 10:\n",
    "                print(f\"‚úÖ Melhoria moderada ({10}-{20}%)\")\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Melhoria marginal (<{10}%)\")\n",
    "    \n",
    "    # Visualizar compara√ß√£o\n",
    "    if len(comparison_results) > 1:\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "        \n",
    "        models = list(comparison_results.keys())\n",
    "        mae_values = [comparison_results[m]['avg_mae'] for m in models]\n",
    "        coverage_values = [comparison_results[m]['avg_coverage'] for m in models]\n",
    "        \n",
    "        # Compara√ß√£o MAE\n",
    "        colors = ['green' if 'CQR' in m else 'blue' for m in models]\n",
    "        bars1 = ax1.bar(models, mae_values, color=colors, alpha=0.7)\n",
    "        ax1.set_title('Compara√ß√£o MAE', fontweight='bold')\n",
    "        ax1.set_ylabel('MAE')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Adicionar valores\n",
    "        for bar, mae in zip(bars1, mae_values):\n",
    "            height = bar.get_height()\n",
    "            ax1.text(bar.get_x() + bar.get_width()/2., height + height*0.01,\n",
    "                    f'{mae:.4f}', ha='center', va='bottom', fontsize=10)\n",
    "        \n",
    "        # Compara√ß√£o Coverage\n",
    "        bars2 = ax2.bar(models, coverage_values, color=colors, alpha=0.7)\n",
    "        ax2.axhline(y=0.90, color='red', linestyle='--', alpha=0.8, label='Target (90%)')\n",
    "        ax2.set_title('Compara√ß√£o Coverage', fontweight='bold')\n",
    "        ax2.set_ylabel('Coverage 90%')\n",
    "        ax2.set_ylim(0.80, 1.0)\n",
    "        ax2.legend()\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Adicionar valores\n",
    "        for bar, cov in zip(bars2, coverage_values):\n",
    "            height = bar.get_height()\n",
    "            ax2.text(bar.get_x() + bar.get_width()/2., height + 0.005,\n",
    "                    f'{cov:.3f}', ha='center', va='bottom', fontsize=10)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.suptitle('‚öñÔ∏è Compara√ß√£o: CQR_LightGBM vs Baseline', fontsize=16, fontweight='bold', y=1.02)\n",
    "        plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Dados de compara√ß√£o n√£o dispon√≠veis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## üéØ 5. Decis√£o Final para Produ√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üèÅ Decis√£o final baseada em todos os crit√©rios\n",
    "print(\"üéØ DECIS√ÉO FINAL PARA PRODU√á√ÉO\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Crit√©rios de aprova√ß√£o\n",
    "criteria = {\n",
    "    'cv_quality': False,\n",
    "    'backtest_approval': False,\n",
    "    'performance_improvement': False,\n",
    "    'technical_validation': False\n",
    "}\n",
    "\n",
    "reasons = []\n",
    "\n",
    "# 1. Verificar qualidade do CV\n",
    "if cv_summary:\n",
    "    cv_coverage_ok = sum(1 for h in cv_summary.values() if 0.87 <= h.get('Coverage_90', 0) <= 0.93)\n",
    "    if cv_coverage_ok >= len(cv_summary) * 0.75:  # 75% dos horizontes OK\n",
    "        criteria['cv_quality'] = True\n",
    "        reasons.append(\"‚úÖ Cross-validation: Coverage adequado na maioria dos horizontes\")\n",
    "    else:\n",
    "        reasons.append(\"‚ùå Cross-validation: Coverage fora do range em muitos horizontes\")\n",
    "else:\n",
    "    reasons.append(\"‚ö†Ô∏è Cross-validation: Dados n√£o dispon√≠veis\")\n",
    "\n",
    "# 2. Verificar aprova√ß√£o no backtest\n",
    "if data['historical_backtest'] and 'gates_summary' in data['historical_backtest']:\n",
    "    cqr_result = data['historical_backtest']['gates_summary'].get('CQR_LightGBM', {})\n",
    "    if cqr_result.get('final_decision') == 'GO':\n",
    "        criteria['backtest_approval'] = True\n",
    "        approval_rate = cqr_result.get('approval_rate', 0)\n",
    "        reasons.append(f\"‚úÖ Backtest hist√≥rico: Aprovado (taxa: {approval_rate:.1%})\")\n",
    "    else:\n",
    "        reasons.append(\"‚ùå Backtest hist√≥rico: N√£o aprovado no sistema de gates\")\n",
    "else:\n",
    "    reasons.append(\"‚ö†Ô∏è Backtest hist√≥rico: Dados n√£o dispon√≠veis\")\n",
    "\n",
    "# 3. Verificar melhoria de performance\n",
    "if 'CQR_LightGBM' in comparison_results and 'HAR-RV_Baseline' in comparison_results:\n",
    "    cqr_mae = comparison_results['CQR_LightGBM']['avg_mae']\n",
    "    baseline_mae = comparison_results['HAR-RV_Baseline']['avg_mae']\n",
    "    \n",
    "    if baseline_mae > 0:\n",
    "        improvement = ((baseline_mae - cqr_mae) / baseline_mae) * 100\n",
    "        if improvement > 10:  # M√≠nimo 10% de melhoria\n",
    "            criteria['performance_improvement'] = True\n",
    "            reasons.append(f\"‚úÖ Performance: Melhoria de {improvement:.1f}% no MAE\")\n",
    "        else:\n",
    "            reasons.append(f\"‚ùå Performance: Melhoria insuficiente ({improvement:.1f}%)\")\n",
    "    else:\n",
    "        reasons.append(\"‚ö†Ô∏è Performance: N√£o foi poss√≠vel calcular melhoria\")\n",
    "else:\n",
    "    reasons.append(\"‚ö†Ô∏è Performance: Dados de compara√ß√£o n√£o dispon√≠veis\")\n",
    "\n",
    "# 4. Verificar valida√ß√£o t√©cnica\n",
    "quality_report_file = MODELS_DIR / 'quality_check_report.json'\n",
    "if quality_report_file.exists():\n",
    "    with open(quality_report_file, 'r') as f:\n",
    "        quality_data = json.load(f)\n",
    "    \n",
    "    overall_quality = quality_data.get('overall_quality', 0)\n",
    "    if overall_quality >= 80:\n",
    "        criteria['technical_validation'] = True\n",
    "        reasons.append(f\"‚úÖ Valida√ß√£o t√©cnica: Score de qualidade {overall_quality:.1f}%\")\n",
    "    else:\n",
    "        reasons.append(f\"‚ùå Valida√ß√£o t√©cnica: Score baixo ({overall_quality:.1f}%)\")\n",
    "else:\n",
    "    reasons.append(\"‚ö†Ô∏è Valida√ß√£o t√©cnica: Execute o notebook de qualidade primeiro\")\n",
    "\n",
    "# Decis√£o final\n",
    "approved_criteria = sum(criteria.values())\n",
    "total_criteria = len(criteria)\n",
    "\n",
    "print(f\"\\nüìä CRIT√âRIOS DE AVALIA√á√ÉO ({approved_criteria}/{total_criteria}):\")\n",
    "for reason in reasons:\n",
    "    print(f\"   {reason}\")\n",
    "\n",
    "# Decis√£o\n",
    "if approved_criteria >= 3:  # Pelo menos 3 dos 4 crit√©rios\n",
    "    final_decision = \"üü¢ APROVADO PARA PRODU√á√ÉO\"\n",
    "    recommendation = \"‚úÖ O modelo CQR_LightGBM est√° pronto para deploy em produ√ß√£o\"\n",
    "    confidence = \"Alta\" if approved_criteria == 4 else \"M√©dia\"\n",
    "elif approved_criteria >= 2:\n",
    "    final_decision = \"üü° APROVA√á√ÉO CONDICIONAL\"\n",
    "    recommendation = \"‚ö†Ô∏è Modelo pode ir para produ√ß√£o com monitoramento refor√ßado\"\n",
    "    confidence = \"M√©dia\"\n",
    "else:\n",
    "    final_decision = \"üî¥ N√ÉO APROVADO\"\n",
    "    recommendation = \"‚ùå Modelo precisa de melhorias antes da produ√ß√£o\"\n",
    "    confidence = \"Baixa\"\n",
    "\n",
    "print(f\"\\nüèÅ DECIS√ÉO FINAL: {final_decision}\")\n",
    "print(f\"üí° RECOMENDA√á√ÉO: {recommendation}\")\n",
    "print(f\"üéØ CONFIAN√áA: {confidence}\")\n",
    "\n",
    "# Salvar decis√£o final\n",
    "final_assessment = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'criteria': criteria,\n",
    "    'approved_criteria': approved_criteria,\n",
    "    'total_criteria': total_criteria,\n",
    "    'final_decision': final_decision,\n",
    "    'recommendation': recommendation,\n",
    "    'confidence': confidence,\n",
    "    'reasons': reasons\n",
    "}\n",
    "\n",
    "assessment_file = MODELS_DIR / 'production_assessment.json'\n",
    "with open(assessment_file, 'w') as f:\n",
    "    json.dump(final_assessment, f, indent=2)\n",
    "\n",
    "print(f\"\\nüíæ Avalia√ß√£o salva em: {assessment_file}\")\n",
    "print(\"\\nüéâ Valida√ß√£o de performance conclu√≠da!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
