{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# ğŸ” VerificaÃ§Ã£o de Qualidade do Modelo CQR_LightGBM\n",
    "\n",
    "**Objetivo**: Verificar a qualidade e integridade dos modelos treinados\n",
    "\n",
    "**Escopo**: \n",
    "- âœ… Carregamento e validaÃ§Ã£o dos artefatos\n",
    "- âœ… VerificaÃ§Ã£o das mÃ©tricas de treinamento\n",
    "- âœ… AnÃ¡lise de feature importance\n",
    "- âœ… ValidaÃ§Ã£o da calibraÃ§Ã£o conforme\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“¦ Imports essenciais\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# ConfiguraÃ§Ã£o visual\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(\"âœ… Bibliotecas carregadas\")\n",
    "print(f\"ğŸ“… AnÃ¡lise executada em: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## ğŸ“‚ 1. Carregamento dos Artefatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“ Definir caminhos\n",
    "PROJECT_ROOT = Path().absolute().parent if Path().absolute().name == 'notebooks' else Path().absolute()\n",
    "MODELS_DIR = PROJECT_ROOT / 'data' / 'processed' / 'preds'\n",
    "\n",
    "print(f\"ğŸ—‚ï¸  DiretÃ³rio do projeto: {PROJECT_ROOT}\")\n",
    "print(f\"ğŸ¤– DiretÃ³rio dos modelos: {MODELS_DIR}\")\n",
    "\n",
    "# Verificar existÃªncia dos arquivos essenciais\n",
    "essential_files = {\n",
    "    'training_summary.json': 'Resumo do treinamento',\n",
    "    'meta_train.json': 'Metadados do modelo',\n",
    "    'cv_metrics.json': 'MÃ©tricas de cross-validation'\n",
    "}\n",
    "\n",
    "print(\"\\nğŸ“‹ VerificaÃ§Ã£o de arquivos essenciais:\")\n",
    "for file, desc in essential_files.items():\n",
    "    file_path = MODELS_DIR / file\n",
    "    status = \"âœ…\" if file_path.exists() else \"âŒ\"\n",
    "    size = f\"({file_path.stat().st_size / 1024:.1f}KB)\" if file_path.exists() else \"\"\n",
    "    print(f\"{status} {desc}: {file} {size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Š Carregar metadados principais\n",
    "with open(MODELS_DIR / 'training_summary.json', 'r') as f:\n",
    "    training_summary = json.load(f)\n",
    "\n",
    "with open(MODELS_DIR / 'meta_train.json', 'r') as f:\n",
    "    meta_train = json.load(f)\n",
    "\n",
    "with open(MODELS_DIR / 'cv_metrics.json', 'r') as f:\n",
    "    cv_metrics = json.load(f)\n",
    "\n",
    "print(\"ğŸ“ˆ RESUMO DO TREINAMENTO\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"ğŸ·ï¸  Pipeline Version: {training_summary.get('pipeline_version', 'N/A')}\")\n",
    "print(f\"â±ï¸  Tempo de ExecuÃ§Ã£o: {training_summary.get('execution_time', 0) / 60:.1f} minutos\")\n",
    "print(f\"ğŸ¯ Horizontes Treinados: {training_summary.get('trained_horizons', [])}\")\n",
    "print(f\"ğŸ”¢ Total de Modelos: {training_summary.get('total_models', 0)}\")\n",
    "print(f\"ğŸ“ Features: {meta_train.get('n_features', 'N/A')}\")\n",
    "print(f\"ğŸ“Š Amostras: {meta_train.get('n_samples_total', 'N/A')}\")\n",
    "print(f\"ğŸ“ Quantis: {meta_train.get('quantiles', [])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## ğŸ¯ 2. VerificaÃ§Ã£o dos Modelos por Horizonte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ” Verificar modelos por horizonte\n",
    "horizons = training_summary.get('trained_horizons', [42, 48, 54, 60])\n",
    "model_status = {}\n",
    "\n",
    "print(\"ğŸ¤– STATUS DOS MODELOS POR HORIZONTE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for horizon in horizons:\n",
    "    model_file = MODELS_DIR / f'models_T{horizon}.joblib'\n",
    "    calib_file = MODELS_DIR / f'calibrators_T{horizon}.joblib'\n",
    "    cv_file = MODELS_DIR / f'cv_metrics_T{horizon}.json'\n",
    "    \n",
    "    # Status dos arquivos\n",
    "    model_exists = model_file.exists()\n",
    "    calib_exists = calib_file.exists()\n",
    "    cv_exists = cv_file.exists()\n",
    "    \n",
    "    # Tamanhos\n",
    "    model_size = model_file.stat().st_size / (1024*1024) if model_exists else 0\n",
    "    calib_size = calib_file.stat().st_size / 1024 if calib_exists else 0\n",
    "    \n",
    "    model_status[horizon] = {\n",
    "        'model_exists': model_exists,\n",
    "        'calib_exists': calib_exists,\n",
    "        'cv_exists': cv_exists,\n",
    "        'model_size_mb': model_size,\n",
    "        'calib_size_kb': calib_size\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nğŸ¯ Horizonte {horizon}H:\")\n",
    "    print(f\"   ğŸ“¦ Modelo: {'âœ…' if model_exists else 'âŒ'} ({model_size:.1f}MB)\")\n",
    "    print(f\"   ğŸ›ï¸  Calibrador: {'âœ…' if calib_exists else 'âŒ'} ({calib_size:.1f}KB)\")\n",
    "    print(f\"   ğŸ“Š CV Metrics: {'âœ…' if cv_exists else 'âŒ'}\")\n",
    "    \n",
    "    # Carregar mÃ©tricas se disponÃ­vel\n",
    "    if cv_exists:\n",
    "        with open(cv_file, 'r') as f:\n",
    "            cv_data = json.load(f)\n",
    "        \n",
    "        # Extrair mÃ©tricas principais\n",
    "        if 'mean_metrics' in cv_data:\n",
    "            mae = cv_data['mean_metrics'].get('MAE', 'N/A')\n",
    "            coverage = cv_data['mean_metrics'].get('Coverage_90', 'N/A')\n",
    "            print(f\"   ğŸ“ˆ MAE MÃ©dio: {mae if mae == 'N/A' else f'{mae:.4f}'}\")\n",
    "            print(f\"   ğŸ¯ Coverage 90%: {coverage if coverage == 'N/A' else f'{coverage:.3f}'}\")\n",
    "\n",
    "# Resumo geral\n",
    "total_models = sum(1 for status in model_status.values() if status['model_exists'])\n",
    "total_calibs = sum(1 for status in model_status.values() if status['calib_exists'])\n",
    "total_size = sum(status['model_size_mb'] for status in model_status.values())\n",
    "\n",
    "print(f\"\\nğŸ“‹ RESUMO GERAL:\")\n",
    "print(f\"âœ… Modelos carregados: {total_models}/{len(horizons)}\")\n",
    "print(f\"âœ… Calibradores: {total_calibs}/{len(horizons)}\")\n",
    "print(f\"ğŸ’¾ Tamanho total: {total_size:.1f}MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## ğŸ“Š 3. AnÃ¡lise de Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“ˆ Carregar e analisar feature importance\n",
    "feature_importance_data = {}\n",
    "\n",
    "print(\"ğŸ” ANÃLISE DE FEATURE IMPORTANCE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for horizon in horizons:\n",
    "    fi_file = MODELS_DIR / f'feature_importance_T{horizon}.csv'\n",
    "    if fi_file.exists():\n",
    "        fi_df = pd.read_csv(fi_file)\n",
    "        feature_importance_data[horizon] = fi_df\n",
    "        \n",
    "        print(f\"\\nğŸ¯ Horizonte {horizon}H - Top 5 Features:\")\n",
    "        \n",
    "        # Usar coluna 'mean' que representa a importÃ¢ncia mÃ©dia\n",
    "        if 'mean' in fi_df.columns and 'feature' in fi_df.columns:\n",
    "            top_features = fi_df.nlargest(5, 'mean')\n",
    "            for i, (idx, row) in enumerate(top_features.iterrows()):\n",
    "                feature_name = row['feature']\n",
    "                importance_val = row['mean']\n",
    "                std_val = row.get('std', 0)\n",
    "                print(f\"   {i+1:2d}. {feature_name:<25} ({importance_val:.1f} Â±{std_val:.1f})\")\n",
    "        else:\n",
    "            print(f\"   ğŸ“‹ Colunas disponÃ­veis: {list(fi_df.columns)}\")\n",
    "\n",
    "# Visualizar feature importance consolidada\n",
    "if feature_importance_data:\n",
    "    print(f\"\\nğŸ“Š Gerando visualizaÃ§Ãµes para {len(feature_importance_data)} horizontes...\")\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, horizon in enumerate(horizons[:4]):\n",
    "        if horizon in feature_importance_data:\n",
    "            fi_df = feature_importance_data[horizon]\n",
    "            \n",
    "            if 'mean' in fi_df.columns and 'feature' in fi_df.columns:\n",
    "                top_10 = fi_df.nlargest(10, 'mean')\n",
    "                \n",
    "                feature_names = top_10['feature'].tolist()\n",
    "                importance_values = top_10['mean'].tolist()\n",
    "                std_values = top_10['std'].tolist() if 'std' in fi_df.columns else [0] * len(importance_values)\n",
    "                \n",
    "                # Criar grÃ¡fico de barras horizontais\n",
    "                y_pos = range(len(importance_values))\n",
    "                colors = plt.cm.viridis(np.linspace(0, 1, len(importance_values)))\n",
    "                \n",
    "                bars = axes[idx].barh(y_pos, importance_values, \n",
    "                                    xerr=std_values, color=colors, alpha=0.8,\n",
    "                                    capsize=3, error_kw={'alpha': 0.6})\n",
    "                \n",
    "                axes[idx].set_yticks(y_pos)\n",
    "                axes[idx].set_yticklabels(feature_names, fontsize=9)\n",
    "                axes[idx].set_title(f'Top 10 Features - {horizon}H', fontsize=12, fontweight='bold')\n",
    "                axes[idx].set_xlabel('ImportÃ¢ncia MÃ©dia')\n",
    "                axes[idx].grid(True, alpha=0.3, axis='x')\n",
    "                \n",
    "                # Adicionar valores nas barras\n",
    "                for i, (bar, val, std) in enumerate(zip(bars, importance_values, std_values)):\n",
    "                    width = bar.get_width()\n",
    "                    axes[idx].text(width + width*0.02, bar.get_y() + bar.get_height()/2., \n",
    "                                  f'{val:.0f}', ha='left', va='center', fontsize=8, fontweight='bold')\n",
    "                \n",
    "                # Inverter ordem para mostrar maior importÃ¢ncia no topo\n",
    "                axes[idx].invert_yaxis()\n",
    "            else:\n",
    "                axes[idx].text(0.5, 0.5, f'Dados nÃ£o disponÃ­veis\\npara horizonte {horizon}H', \n",
    "                              ha='center', va='center', transform=axes[idx].transAxes,\n",
    "                              fontsize=12, bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgray\"))\n",
    "                axes[idx].set_xticks([])\n",
    "                axes[idx].set_yticks([])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('ğŸ¯ Feature Importance por Horizonte (LightGBM)', fontsize=16, fontweight='bold', y=1.02)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nğŸ“Š GrÃ¡fico de Feature Importance gerado!\")\n",
    "    \n",
    "    # AnÃ¡lise adicional das features mais importantes\n",
    "    if len(feature_importance_data) > 0:\n",
    "        print(f\"\\nğŸ” ANÃLISE CONSOLIDADA:\")\n",
    "        \n",
    "        # Encontrar features que aparecem no top 5 em mÃºltiplos horizontes\n",
    "        all_top_features = {}\n",
    "        for horizon, fi_df in feature_importance_data.items():\n",
    "            if 'mean' in fi_df.columns and 'feature' in fi_df.columns:\n",
    "                top_5 = fi_df.nlargest(5, 'mean')\n",
    "                for _, row in top_5.iterrows():\n",
    "                    feature = row['feature']\n",
    "                    if feature not in all_top_features:\n",
    "                        all_top_features[feature] = []\n",
    "                    all_top_features[feature].append(horizon)\n",
    "        \n",
    "        # Features mais consistentes (aparecem em mÃºltiplos horizontes)\n",
    "        consistent_features = {k: v for k, v in all_top_features.items() if len(v) >= 2}\n",
    "        \n",
    "        if consistent_features:\n",
    "            print(f\"   ğŸ† Features consistentes (top 5 em mÃºltiplos horizontes):\")\n",
    "            for feature, horizons in sorted(consistent_features.items(), key=lambda x: len(x[1]), reverse=True):\n",
    "                print(f\"      â€¢ {feature:<30} (horizontes: {horizons})\")\n",
    "        \n",
    "        # EstatÃ­stica geral\n",
    "        total_features = sum(len(fi_df) for fi_df in feature_importance_data.values())\n",
    "        avg_importance = np.mean([fi_df['mean'].mean() for fi_df in feature_importance_data.values()])\n",
    "        \n",
    "        print(f\"   ğŸ“Š Total de features analisadas: {total_features}\")\n",
    "        print(f\"   ğŸ“ˆ ImportÃ¢ncia mÃ©dia geral: {avg_importance:.1f}\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nâš ï¸ Nenhum arquivo de feature importance encontrado\")\n",
    "    print(\"   ğŸ’¡ Verifique se o treinamento foi executado com flag de feature importance ativo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## ğŸ›ï¸ 4. ValidaÃ§Ã£o da CalibraÃ§Ã£o Conforme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¯ Verificar calibradores conformes\n",
    "print(\"ğŸ›ï¸ VALIDAÃ‡ÃƒO DOS CALIBRADORES CONFORMES\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "calibration_status = {}\n",
    "\n",
    "for horizon in horizons:\n",
    "    calib_file = MODELS_DIR / f'calibrators_T{horizon}.joblib'\n",
    "    calib_json = MODELS_DIR / f'calib_T{horizon}.json'\n",
    "    \n",
    "    if calib_file.exists() and calib_json.exists():\n",
    "        # Carregar calibradores\n",
    "        calibrators = joblib.load(calib_file)\n",
    "        \n",
    "        with open(calib_json, 'r') as f:\n",
    "            calib_data = json.load(f)\n",
    "        \n",
    "        print(f\"\\nğŸ¯ Horizonte {horizon}H:\")\n",
    "        print(f\"   ğŸ“¦ Calibradores carregados: {len(calibrators) if isinstance(calibrators, (list, dict)) else 1}\")\n",
    "        \n",
    "        # Verificar dados de calibraÃ§Ã£o\n",
    "        if 'alpha' in calib_data:\n",
    "            alpha = calib_data['alpha']\n",
    "            confidence = (1 - alpha) * 100\n",
    "            print(f\"   ğŸ¯ NÃ­vel de confianÃ§a: {confidence:.0f}% (Î±={alpha})\")\n",
    "        \n",
    "        if 'n_calibration_samples' in calib_data:\n",
    "            n_samples = calib_data['n_calibration_samples']\n",
    "            print(f\"   ğŸ“Š Amostras de calibraÃ§Ã£o: {n_samples:,}\")\n",
    "        \n",
    "        if 'quantiles_coverage' in calib_data:\n",
    "            coverage = calib_data['quantiles_coverage']\n",
    "            print(f\"   ğŸ“ˆ Coverage observado: {coverage:.3f}\")\n",
    "            \n",
    "            # Verificar se estÃ¡ dentro da tolerÃ¢ncia esperada (90% Â± 3%)\n",
    "            target_coverage = 0.90\n",
    "            tolerance = 0.03\n",
    "            in_range = abs(coverage - target_coverage) <= tolerance\n",
    "            status_icon = \"âœ…\" if in_range else \"âš ï¸\"\n",
    "            print(f\"   {status_icon} Status: {'OK' if in_range else 'ATENÃ‡ÃƒO'} (target: {target_coverage:.0%} Â± {tolerance:.0%})\")\n",
    "            \n",
    "            calibration_status[horizon] = {\n",
    "                'coverage': coverage,\n",
    "                'in_range': in_range,\n",
    "                'n_samples': n_samples if 'n_calibration_samples' in calib_data else 'N/A'\n",
    "            }\n",
    "    else:\n",
    "        print(f\"\\nâŒ Horizonte {horizon}H: Arquivos de calibraÃ§Ã£o nÃ£o encontrados\")\n",
    "        calibration_status[horizon] = {'coverage': None, 'in_range': False, 'n_samples': 0}\n",
    "\n",
    "# Resumo da calibraÃ§Ã£o\n",
    "valid_calibrations = sum(1 for status in calibration_status.values() if status['in_range'])\n",
    "total_calibrations = len([s for s in calibration_status.values() if s['coverage'] is not None])\n",
    "\n",
    "print(f\"\\nğŸ“‹ RESUMO DA CALIBRAÃ‡ÃƒO:\")\n",
    "print(f\"âœ… CalibraÃ§Ãµes vÃ¡lidas: {valid_calibrations}/{total_calibrations}\")\n",
    "if total_calibrations > 0:\n",
    "    avg_coverage = np.mean([s['coverage'] for s in calibration_status.values() if s['coverage'] is not None])\n",
    "    print(f\"ğŸ“Š Coverage mÃ©dio: {avg_coverage:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## âœ… 5. RelatÃ³rio Final de Qualidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“‹ Gerar relatÃ³rio final de qualidade\n",
    "print(\"ğŸ“‹ RELATÃ“RIO FINAL DE QUALIDADE DO MODELO\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Calcular scores de qualidade\n",
    "quality_scores = {\n",
    "    'completeness': (total_models / len(horizons)) * 100,\n",
    "    'calibration': (valid_calibrations / len(horizons)) * 100 if len(horizons) > 0 else 0,\n",
    "    'size_consistency': 100 if all(s['model_size_mb'] > 1 for s in model_status.values()) else 50\n",
    "}\n",
    "\n",
    "overall_quality = np.mean(list(quality_scores.values()))\n",
    "\n",
    "print(f\"\\nğŸ¯ SCORES DE QUALIDADE:\")\n",
    "print(f\"   ğŸ“¦ Completeness: {quality_scores['completeness']:.1f}%\")\n",
    "print(f\"   ğŸ›ï¸  CalibraÃ§Ã£o: {quality_scores['calibration']:.1f}%\")\n",
    "print(f\"   ğŸ’¾ ConsistÃªncia: {quality_scores['size_consistency']:.1f}%\")\n",
    "print(f\"   ğŸ† Score Geral: {overall_quality:.1f}%\")\n",
    "\n",
    "# Determinar status final\n",
    "if overall_quality >= 90:\n",
    "    status = \"ğŸŸ¢ EXCELENTE\"\n",
    "    recommendation = \"âœ… Modelo pronto para produÃ§Ã£o\"\n",
    "elif overall_quality >= 75:\n",
    "    status = \"ğŸŸ¡ BOM\"\n",
    "    recommendation = \"âš ï¸ Verificar pontos de atenÃ§Ã£o antes da produÃ§Ã£o\"\n",
    "else:\n",
    "    status = \"ğŸ”´ ATENÃ‡ÃƒO\"\n",
    "    recommendation = \"âŒ NecessÃ¡ria revisÃ£o antes da produÃ§Ã£o\"\n",
    "\n",
    "print(f\"\\nğŸ¯ STATUS FINAL: {status}\")\n",
    "print(f\"ğŸ’¡ RECOMENDAÃ‡ÃƒO: {recommendation}\")\n",
    "\n",
    "# Salvar resumo\n",
    "quality_report = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'model_status': model_status,\n",
    "    'calibration_status': calibration_status,\n",
    "    'quality_scores': quality_scores,\n",
    "    'overall_quality': overall_quality,\n",
    "    'status': status,\n",
    "    'recommendation': recommendation\n",
    "}\n",
    "\n",
    "report_file = MODELS_DIR / 'quality_check_report.json'\n",
    "with open(report_file, 'w') as f:\n",
    "    json.dump(quality_report, f, indent=2, default=str)\n",
    "\n",
    "print(f\"\\nğŸ’¾ RelatÃ³rio salvo em: {report_file}\")\n",
    "print(\"\\nğŸ‰ VerificaÃ§Ã£o de qualidade concluÃ­da!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
