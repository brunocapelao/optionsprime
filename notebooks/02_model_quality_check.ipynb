{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# 🔍 Verificação de Qualidade do Modelo CQR_LightGBM\n",
    "\n",
    "**Objetivo**: Verificar a qualidade e integridade dos modelos treinados\n",
    "\n",
    "**Escopo**: \n",
    "- ✅ Carregamento e validação dos artefatos\n",
    "- ✅ Verificação das métricas de treinamento\n",
    "- ✅ Análise de feature importance\n",
    "- ✅ Validação da calibração conforme\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📦 Imports essenciais\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuração visual\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(\"✅ Bibliotecas carregadas\")\n",
    "print(f\"📅 Análise executada em: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## 📂 1. Carregamento dos Artefatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📁 Definir caminhos\n",
    "PROJECT_ROOT = Path().absolute().parent if Path().absolute().name == 'notebooks' else Path().absolute()\n",
    "MODELS_DIR = PROJECT_ROOT / 'data' / 'processed' / 'preds'\n",
    "\n",
    "print(f\"🗂️  Diretório do projeto: {PROJECT_ROOT}\")\n",
    "print(f\"🤖 Diretório dos modelos: {MODELS_DIR}\")\n",
    "\n",
    "# Verificar existência dos arquivos essenciais\n",
    "essential_files = {\n",
    "    'training_summary.json': 'Resumo do treinamento',\n",
    "    'meta_train.json': 'Metadados do modelo',\n",
    "    'cv_metrics.json': 'Métricas de cross-validation'\n",
    "}\n",
    "\n",
    "print(\"\\n📋 Verificação de arquivos essenciais:\")\n",
    "for file, desc in essential_files.items():\n",
    "    file_path = MODELS_DIR / file\n",
    "    status = \"✅\" if file_path.exists() else \"❌\"\n",
    "    size = f\"({file_path.stat().st_size / 1024:.1f}KB)\" if file_path.exists() else \"\"\n",
    "    print(f\"{status} {desc}: {file} {size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📊 Carregar metadados principais\n",
    "with open(MODELS_DIR / 'training_summary.json', 'r') as f:\n",
    "    training_summary = json.load(f)\n",
    "\n",
    "with open(MODELS_DIR / 'meta_train.json', 'r') as f:\n",
    "    meta_train = json.load(f)\n",
    "\n",
    "with open(MODELS_DIR / 'cv_metrics.json', 'r') as f:\n",
    "    cv_metrics = json.load(f)\n",
    "\n",
    "print(\"📈 RESUMO DO TREINAMENTO\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"🏷️  Pipeline Version: {training_summary.get('pipeline_version', 'N/A')}\")\n",
    "print(f\"⏱️  Tempo de Execução: {training_summary.get('execution_time', 0) / 60:.1f} minutos\")\n",
    "print(f\"🎯 Horizontes Treinados: {training_summary.get('trained_horizons', [])}\")\n",
    "print(f\"🔢 Total de Modelos: {training_summary.get('total_models', 0)}\")\n",
    "print(f\"📏 Features: {meta_train.get('n_features', 'N/A')}\")\n",
    "print(f\"📊 Amostras: {meta_train.get('n_samples_total', 'N/A')}\")\n",
    "print(f\"📐 Quantis: {meta_train.get('quantiles', [])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## 🎯 2. Verificação dos Modelos por Horizonte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔍 Verificar modelos por horizonte\n",
    "horizons = training_summary.get('trained_horizons', [42, 48, 54, 60])\n",
    "model_status = {}\n",
    "\n",
    "print(\"🤖 STATUS DOS MODELOS POR HORIZONTE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for horizon in horizons:\n",
    "    model_file = MODELS_DIR / f'models_T{horizon}.joblib'\n",
    "    calib_file = MODELS_DIR / f'calibrators_T{horizon}.joblib'\n",
    "    cv_file = MODELS_DIR / f'cv_metrics_T{horizon}.json'\n",
    "    \n",
    "    # Status dos arquivos\n",
    "    model_exists = model_file.exists()\n",
    "    calib_exists = calib_file.exists()\n",
    "    cv_exists = cv_file.exists()\n",
    "    \n",
    "    # Tamanhos\n",
    "    model_size = model_file.stat().st_size / (1024*1024) if model_exists else 0\n",
    "    calib_size = calib_file.stat().st_size / 1024 if calib_exists else 0\n",
    "    \n",
    "    model_status[horizon] = {\n",
    "        'model_exists': model_exists,\n",
    "        'calib_exists': calib_exists,\n",
    "        'cv_exists': cv_exists,\n",
    "        'model_size_mb': model_size,\n",
    "        'calib_size_kb': calib_size\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n🎯 Horizonte {horizon}H:\")\n",
    "    print(f\"   📦 Modelo: {'✅' if model_exists else '❌'} ({model_size:.1f}MB)\")\n",
    "    print(f\"   🎛️  Calibrador: {'✅' if calib_exists else '❌'} ({calib_size:.1f}KB)\")\n",
    "    print(f\"   📊 CV Metrics: {'✅' if cv_exists else '❌'}\")\n",
    "    \n",
    "    # Carregar métricas se disponível\n",
    "    if cv_exists:\n",
    "        with open(cv_file, 'r') as f:\n",
    "            cv_data = json.load(f)\n",
    "        \n",
    "        # Extrair métricas principais\n",
    "        if 'mean_metrics' in cv_data:\n",
    "            mae = cv_data['mean_metrics'].get('MAE', 'N/A')\n",
    "            coverage = cv_data['mean_metrics'].get('Coverage_90', 'N/A')\n",
    "            print(f\"   📈 MAE Médio: {mae if mae == 'N/A' else f'{mae:.4f}'}\")\n",
    "            print(f\"   🎯 Coverage 90%: {coverage if coverage == 'N/A' else f'{coverage:.3f}'}\")\n",
    "\n",
    "# Resumo geral\n",
    "total_models = sum(1 for status in model_status.values() if status['model_exists'])\n",
    "total_calibs = sum(1 for status in model_status.values() if status['calib_exists'])\n",
    "total_size = sum(status['model_size_mb'] for status in model_status.values())\n",
    "\n",
    "print(f\"\\n📋 RESUMO GERAL:\")\n",
    "print(f\"✅ Modelos carregados: {total_models}/{len(horizons)}\")\n",
    "print(f\"✅ Calibradores: {total_calibs}/{len(horizons)}\")\n",
    "print(f\"💾 Tamanho total: {total_size:.1f}MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## 📊 3. Análise de Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📈 Carregar e analisar feature importance\n",
    "feature_importance_data = {}\n",
    "\n",
    "print(\"🔍 ANÁLISE DE FEATURE IMPORTANCE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for horizon in horizons:\n",
    "    fi_file = MODELS_DIR / f'feature_importance_T{horizon}.csv'\n",
    "    if fi_file.exists():\n",
    "        fi_df = pd.read_csv(fi_file)\n",
    "        feature_importance_data[horizon] = fi_df\n",
    "        \n",
    "        print(f\"\\n🎯 Horizonte {horizon}H - Top 5 Features:\")\n",
    "        \n",
    "        # Usar coluna 'mean' que representa a importância média\n",
    "        if 'mean' in fi_df.columns and 'feature' in fi_df.columns:\n",
    "            top_features = fi_df.nlargest(5, 'mean')\n",
    "            for i, (idx, row) in enumerate(top_features.iterrows()):\n",
    "                feature_name = row['feature']\n",
    "                importance_val = row['mean']\n",
    "                std_val = row.get('std', 0)\n",
    "                print(f\"   {i+1:2d}. {feature_name:<25} ({importance_val:.1f} ±{std_val:.1f})\")\n",
    "        else:\n",
    "            print(f\"   📋 Colunas disponíveis: {list(fi_df.columns)}\")\n",
    "\n",
    "# Visualizar feature importance consolidada\n",
    "if feature_importance_data:\n",
    "    print(f\"\\n📊 Gerando visualizações para {len(feature_importance_data)} horizontes...\")\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, horizon in enumerate(horizons[:4]):\n",
    "        if horizon in feature_importance_data:\n",
    "            fi_df = feature_importance_data[horizon]\n",
    "            \n",
    "            if 'mean' in fi_df.columns and 'feature' in fi_df.columns:\n",
    "                top_10 = fi_df.nlargest(10, 'mean')\n",
    "                \n",
    "                feature_names = top_10['feature'].tolist()\n",
    "                importance_values = top_10['mean'].tolist()\n",
    "                std_values = top_10['std'].tolist() if 'std' in fi_df.columns else [0] * len(importance_values)\n",
    "                \n",
    "                # Criar gráfico de barras horizontais\n",
    "                y_pos = range(len(importance_values))\n",
    "                colors = plt.cm.viridis(np.linspace(0, 1, len(importance_values)))\n",
    "                \n",
    "                bars = axes[idx].barh(y_pos, importance_values, \n",
    "                                    xerr=std_values, color=colors, alpha=0.8,\n",
    "                                    capsize=3, error_kw={'alpha': 0.6})\n",
    "                \n",
    "                axes[idx].set_yticks(y_pos)\n",
    "                axes[idx].set_yticklabels(feature_names, fontsize=9)\n",
    "                axes[idx].set_title(f'Top 10 Features - {horizon}H', fontsize=12, fontweight='bold')\n",
    "                axes[idx].set_xlabel('Importância Média')\n",
    "                axes[idx].grid(True, alpha=0.3, axis='x')\n",
    "                \n",
    "                # Adicionar valores nas barras\n",
    "                for i, (bar, val, std) in enumerate(zip(bars, importance_values, std_values)):\n",
    "                    width = bar.get_width()\n",
    "                    axes[idx].text(width + width*0.02, bar.get_y() + bar.get_height()/2., \n",
    "                                  f'{val:.0f}', ha='left', va='center', fontsize=8, fontweight='bold')\n",
    "                \n",
    "                # Inverter ordem para mostrar maior importância no topo\n",
    "                axes[idx].invert_yaxis()\n",
    "            else:\n",
    "                axes[idx].text(0.5, 0.5, f'Dados não disponíveis\\npara horizonte {horizon}H', \n",
    "                              ha='center', va='center', transform=axes[idx].transAxes,\n",
    "                              fontsize=12, bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgray\"))\n",
    "                axes[idx].set_xticks([])\n",
    "                axes[idx].set_yticks([])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('🎯 Feature Importance por Horizonte (LightGBM)', fontsize=16, fontweight='bold', y=1.02)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n📊 Gráfico de Feature Importance gerado!\")\n",
    "    \n",
    "    # Análise adicional das features mais importantes\n",
    "    if len(feature_importance_data) > 0:\n",
    "        print(f\"\\n🔍 ANÁLISE CONSOLIDADA:\")\n",
    "        \n",
    "        # Encontrar features que aparecem no top 5 em múltiplos horizontes\n",
    "        all_top_features = {}\n",
    "        for horizon, fi_df in feature_importance_data.items():\n",
    "            if 'mean' in fi_df.columns and 'feature' in fi_df.columns:\n",
    "                top_5 = fi_df.nlargest(5, 'mean')\n",
    "                for _, row in top_5.iterrows():\n",
    "                    feature = row['feature']\n",
    "                    if feature not in all_top_features:\n",
    "                        all_top_features[feature] = []\n",
    "                    all_top_features[feature].append(horizon)\n",
    "        \n",
    "        # Features mais consistentes (aparecem em múltiplos horizontes)\n",
    "        consistent_features = {k: v for k, v in all_top_features.items() if len(v) >= 2}\n",
    "        \n",
    "        if consistent_features:\n",
    "            print(f\"   🏆 Features consistentes (top 5 em múltiplos horizontes):\")\n",
    "            for feature, horizons in sorted(consistent_features.items(), key=lambda x: len(x[1]), reverse=True):\n",
    "                print(f\"      • {feature:<30} (horizontes: {horizons})\")\n",
    "        \n",
    "        # Estatística geral\n",
    "        total_features = sum(len(fi_df) for fi_df in feature_importance_data.values())\n",
    "        avg_importance = np.mean([fi_df['mean'].mean() for fi_df in feature_importance_data.values()])\n",
    "        \n",
    "        print(f\"   📊 Total de features analisadas: {total_features}\")\n",
    "        print(f\"   📈 Importância média geral: {avg_importance:.1f}\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n⚠️ Nenhum arquivo de feature importance encontrado\")\n",
    "    print(\"   💡 Verifique se o treinamento foi executado com flag de feature importance ativo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## 🎛️ 4. Validação da Calibração Conforme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🎯 Verificar calibradores conformes\n",
    "print(\"🎛️ VALIDAÇÃO DOS CALIBRADORES CONFORMES\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "calibration_status = {}\n",
    "\n",
    "for horizon in horizons:\n",
    "    calib_file = MODELS_DIR / f'calibrators_T{horizon}.joblib'\n",
    "    calib_json = MODELS_DIR / f'calib_T{horizon}.json'\n",
    "    \n",
    "    if calib_file.exists() and calib_json.exists():\n",
    "        # Carregar calibradores\n",
    "        calibrators = joblib.load(calib_file)\n",
    "        \n",
    "        with open(calib_json, 'r') as f:\n",
    "            calib_data = json.load(f)\n",
    "        \n",
    "        print(f\"\\n🎯 Horizonte {horizon}H:\")\n",
    "        print(f\"   📦 Calibradores carregados: {len(calibrators) if isinstance(calibrators, (list, dict)) else 1}\")\n",
    "        \n",
    "        # Verificar dados de calibração\n",
    "        if 'alpha' in calib_data:\n",
    "            alpha = calib_data['alpha']\n",
    "            confidence = (1 - alpha) * 100\n",
    "            print(f\"   🎯 Nível de confiança: {confidence:.0f}% (α={alpha})\")\n",
    "        \n",
    "        if 'n_calibration_samples' in calib_data:\n",
    "            n_samples = calib_data['n_calibration_samples']\n",
    "            print(f\"   📊 Amostras de calibração: {n_samples:,}\")\n",
    "        \n",
    "        if 'quantiles_coverage' in calib_data:\n",
    "            coverage = calib_data['quantiles_coverage']\n",
    "            print(f\"   📈 Coverage observado: {coverage:.3f}\")\n",
    "            \n",
    "            # Verificar se está dentro da tolerância esperada (90% ± 3%)\n",
    "            target_coverage = 0.90\n",
    "            tolerance = 0.03\n",
    "            in_range = abs(coverage - target_coverage) <= tolerance\n",
    "            status_icon = \"✅\" if in_range else \"⚠️\"\n",
    "            print(f\"   {status_icon} Status: {'OK' if in_range else 'ATENÇÃO'} (target: {target_coverage:.0%} ± {tolerance:.0%})\")\n",
    "            \n",
    "            calibration_status[horizon] = {\n",
    "                'coverage': coverage,\n",
    "                'in_range': in_range,\n",
    "                'n_samples': n_samples if 'n_calibration_samples' in calib_data else 'N/A'\n",
    "            }\n",
    "    else:\n",
    "        print(f\"\\n❌ Horizonte {horizon}H: Arquivos de calibração não encontrados\")\n",
    "        calibration_status[horizon] = {'coverage': None, 'in_range': False, 'n_samples': 0}\n",
    "\n",
    "# Resumo da calibração\n",
    "valid_calibrations = sum(1 for status in calibration_status.values() if status['in_range'])\n",
    "total_calibrations = len([s for s in calibration_status.values() if s['coverage'] is not None])\n",
    "\n",
    "print(f\"\\n📋 RESUMO DA CALIBRAÇÃO:\")\n",
    "print(f\"✅ Calibrações válidas: {valid_calibrations}/{total_calibrations}\")\n",
    "if total_calibrations > 0:\n",
    "    avg_coverage = np.mean([s['coverage'] for s in calibration_status.values() if s['coverage'] is not None])\n",
    "    print(f\"📊 Coverage médio: {avg_coverage:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## ✅ 5. Relatório Final de Qualidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📋 Gerar relatório final de qualidade\n",
    "print(\"📋 RELATÓRIO FINAL DE QUALIDADE DO MODELO\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Calcular scores de qualidade\n",
    "quality_scores = {\n",
    "    'completeness': (total_models / len(horizons)) * 100,\n",
    "    'calibration': (valid_calibrations / len(horizons)) * 100 if len(horizons) > 0 else 0,\n",
    "    'size_consistency': 100 if all(s['model_size_mb'] > 1 for s in model_status.values()) else 50\n",
    "}\n",
    "\n",
    "overall_quality = np.mean(list(quality_scores.values()))\n",
    "\n",
    "print(f\"\\n🎯 SCORES DE QUALIDADE:\")\n",
    "print(f\"   📦 Completeness: {quality_scores['completeness']:.1f}%\")\n",
    "print(f\"   🎛️  Calibração: {quality_scores['calibration']:.1f}%\")\n",
    "print(f\"   💾 Consistência: {quality_scores['size_consistency']:.1f}%\")\n",
    "print(f\"   🏆 Score Geral: {overall_quality:.1f}%\")\n",
    "\n",
    "# Determinar status final\n",
    "if overall_quality >= 90:\n",
    "    status = \"🟢 EXCELENTE\"\n",
    "    recommendation = \"✅ Modelo pronto para produção\"\n",
    "elif overall_quality >= 75:\n",
    "    status = \"🟡 BOM\"\n",
    "    recommendation = \"⚠️ Verificar pontos de atenção antes da produção\"\n",
    "else:\n",
    "    status = \"🔴 ATENÇÃO\"\n",
    "    recommendation = \"❌ Necessária revisão antes da produção\"\n",
    "\n",
    "print(f\"\\n🎯 STATUS FINAL: {status}\")\n",
    "print(f\"💡 RECOMENDAÇÃO: {recommendation}\")\n",
    "\n",
    "# Salvar resumo\n",
    "quality_report = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'model_status': model_status,\n",
    "    'calibration_status': calibration_status,\n",
    "    'quality_scores': quality_scores,\n",
    "    'overall_quality': overall_quality,\n",
    "    'status': status,\n",
    "    'recommendation': recommendation\n",
    "}\n",
    "\n",
    "report_file = MODELS_DIR / 'quality_check_report.json'\n",
    "with open(report_file, 'w') as f:\n",
    "    json.dump(quality_report, f, indent=2, default=str)\n",
    "\n",
    "print(f\"\\n💾 Relatório salvo em: {report_file}\")\n",
    "print(\"\\n🎉 Verificação de qualidade concluída!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
