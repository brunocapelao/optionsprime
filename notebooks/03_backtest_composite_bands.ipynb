{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5abe8ac7",
   "metadata": {},
   "source": [
    "# 🧪 Backtest de Faixas Compostas - Pseudo-Backtest\n",
    "\n",
    "Este notebook avalia a qualidade das **faixas compostas** através de um pseudo-backtest.\n",
    "\n",
    "## 📋 Metodologia\n",
    "\n",
    "- **Tipo**: Pseudo-backtest (modelo atual aplicado a dados históricos)\n",
    "- **Período**: Últimos N pontos temporais disponíveis\n",
    "- **Horizonte**: T=42, 48, 54, 60 barras de 4H (7-10 dias)\n",
    "- **Abordagem Composta**: Cada data futura usa a previsão do modelo específico para aquele horizonte\n",
    "\n",
    "## ⚠️ Limitação: Look-Ahead Bias\n",
    "\n",
    "Como estamos usando o modelo atual (treinado até hoje) para avaliar previsões no passado,\n",
    "existe um **viés de look-ahead**: o modelo \"viu\" os dados que estamos testando durante o treinamento.\n",
    "\n",
    "**Interpretação correta:**\n",
    "- ✅ Válido para avaliar **calibração** das faixas (coverage dos intervalos)\n",
    "- ✅ Válido para avaliar **consistência** temporal\n",
    "- ⚠️ Limitado para avaliar **poder preditivo absoluto** (otimista demais)\n",
    "\n",
    "## 🎯 Objetivos\n",
    "\n",
    "1. Verificar se os intervalos de confiança estão bem calibrados (90% CI ≈ 90%, 50% CI ≈ 50%)\n",
    "2. Avaliar sharpness (largura) das faixas\n",
    "3. Analisar erros da mediana (p50)\n",
    "4. Identificar padrões temporais e regimes de mercado\n",
    "5. Comparar faixas compostas vs modelos individuais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d7f8db",
   "metadata": {},
   "source": [
    "## 1. Setup e Configuração"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a09775c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Imports carregados\n",
      "📅 Data: 2025-10-02 18:07:11\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurações de visualização\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (16, 10)\n",
    "plt.rcParams['font.size'] = 10\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"✅ Imports carregados\")\n",
    "print(f\"📅 Data: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37828f44",
   "metadata": {},
   "source": [
    "### Parâmetros do Backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26651875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚙️ Configuração do Backtest:\n",
      "   horizons: [42, 48, 54, 60]\n",
      "   n_backtest_points: 50\n",
      "   bar_frequency_hours: 4\n",
      "   confidence_levels: [0.9, 0.5]\n",
      "   tolerance_hours: 4\n"
     ]
    }
   ],
   "source": [
    "# Configurações\n",
    "CONFIG = {\n",
    "    'horizons': [42, 48, 54, 60],  # Horizontes em barras de 4H\n",
    "    'n_backtest_points': 50,        # Quantos pontos ts0 avaliar\n",
    "    'bar_frequency_hours': 4,       # Frequência dos dados\n",
    "    'confidence_levels': [0.90, 0.50],  # Níveis de confiança a avaliar\n",
    "    'tolerance_hours': 4,           # Tolerância para matching temporal\n",
    "}\n",
    "\n",
    "# Caminhos\n",
    "data_dir = Path('../data/processed')\n",
    "features_path = data_dir / 'features' / 'features_4H.parquet'\n",
    "preds_dir = data_dir / 'preds'\n",
    "output_dir = data_dir / 'models' / 'report'\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"⚙️ Configuração do Backtest:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"   {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349173c3",
   "metadata": {},
   "source": [
    "### Funções Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e786ad89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Funções auxiliares definidas:\n",
      "   • get_realized_price()\n",
      "   • calculate_coverage()\n",
      "   • pinball_loss()\n",
      "   • calculate_sharpness()\n"
     ]
    }
   ],
   "source": [
    "def get_realized_price(ts_forecast: pd.Timestamp, df_features: pd.DataFrame, \n",
    "                       tolerance_hours: int = 4) -> float:\n",
    "    \"\"\"\n",
    "    Busca o preço realizado mais próximo de ts_forecast.\n",
    "    \n",
    "    Args:\n",
    "        ts_forecast: Data alvo da previsão\n",
    "        df_features: DataFrame com dados históricos\n",
    "        tolerance_hours: Tolerância máxima em horas\n",
    "    \n",
    "    Returns:\n",
    "        Preço realizado (close) ou None se não encontrado\n",
    "    \"\"\"\n",
    "    # Calcular diferença temporal\n",
    "    df_features['time_diff'] = (df_features['ts'] - ts_forecast).abs()\n",
    "    \n",
    "    # Encontrar o mais próximo\n",
    "    closest_idx = df_features['time_diff'].idxmin()\n",
    "    closest_row = df_features.loc[closest_idx]\n",
    "    \n",
    "    # Verificar se está dentro da tolerância\n",
    "    if closest_row['time_diff'] <= pd.Timedelta(hours=tolerance_hours):\n",
    "        return closest_row['close']\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def calculate_coverage(y_true: np.ndarray, y_lower: np.ndarray, \n",
    "                       y_upper: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Calcula a cobertura de um intervalo de confiança.\n",
    "    \n",
    "    Args:\n",
    "        y_true: Valores reais\n",
    "        y_lower: Limite inferior do intervalo\n",
    "        y_upper: Limite superior do intervalo\n",
    "    \n",
    "    Returns:\n",
    "        Percentual de vezes que y_true está dentro do intervalo\n",
    "    \"\"\"\n",
    "    within_interval = (y_true >= y_lower) & (y_true <= y_upper)\n",
    "    return np.mean(within_interval) * 100\n",
    "\n",
    "\n",
    "def pinball_loss(y_true: np.ndarray, y_pred: np.ndarray, \n",
    "                 quantile: float) -> float:\n",
    "    \"\"\"\n",
    "    Calcula o Pinball Loss para avaliação de quantis.\n",
    "    \n",
    "    Args:\n",
    "        y_true: Valores reais\n",
    "        y_pred: Valores previstos\n",
    "        quantile: Nível do quantil (0-1)\n",
    "    \n",
    "    Returns:\n",
    "        Pinball loss médio\n",
    "    \"\"\"\n",
    "    error = y_true - y_pred\n",
    "    loss = np.where(error >= 0, \n",
    "                    quantile * error, \n",
    "                    (quantile - 1) * error)\n",
    "    return np.mean(loss)\n",
    "\n",
    "\n",
    "def calculate_sharpness(y_lower: np.ndarray, y_upper: np.ndarray, \n",
    "                        s0: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Calcula a largura média do intervalo (normalizada por S0).\n",
    "    \n",
    "    Args:\n",
    "        y_lower: Limite inferior\n",
    "        y_upper: Limite superior\n",
    "        s0: Preço de referência\n",
    "    \n",
    "    Returns:\n",
    "        Largura média em percentual\n",
    "    \"\"\"\n",
    "    width = (y_upper - y_lower) / s0 * 100\n",
    "    return np.mean(width)\n",
    "\n",
    "\n",
    "print(\"✅ Funções auxiliares definidas:\")\n",
    "print(\"   • get_realized_price()\")\n",
    "print(\"   • calculate_coverage()\")\n",
    "print(\"   • pinball_loss()\")\n",
    "print(\"   • calculate_sharpness()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35da5d3",
   "metadata": {},
   "source": [
    "## 2. Carregamento de Dados Históricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bfab498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Carregando dados históricos...\n",
      "   ✓ Features: 32,525 linhas\n",
      "   ✓ Período: 2010-09-07 08:00:00+00:00 a 2025-10-02 00:00:00+00:00\n",
      "   ✓ Colunas: ['ts', 'asset', 'open', 'high', 'low', 'close', 'volume', 'dollar_vol_4h', 'is_gap', 'n_1h_missing']...\n",
      "\n",
      "📂 Carregando predições atuais...\n",
      "   ✓ T=42: 181 predições\n",
      "   ✓ T=48: 181 predições\n",
      "   ✓ T=54: 181 predições\n",
      "   ✓ T=60: 181 predições\n",
      "\n",
      "✅ 4 arquivos de predição carregados\n"
     ]
    }
   ],
   "source": [
    "# Carregar features (preços históricos)\n",
    "print(\"📂 Carregando dados históricos...\")\n",
    "df_features = pd.read_parquet(features_path)\n",
    "df_features['ts'] = pd.to_datetime(df_features['ts'], utc=True)\n",
    "df_features = df_features.sort_values('ts').reset_index(drop=True)\n",
    "\n",
    "print(f\"   ✓ Features: {len(df_features):,} linhas\")\n",
    "print(f\"   ✓ Período: {df_features['ts'].min()} a {df_features['ts'].max()}\")\n",
    "print(f\"   ✓ Colunas: {list(df_features.columns[:10])}...\")\n",
    "\n",
    "# Carregar predições atuais (para usar como template)\n",
    "print(\"\\n📂 Carregando predições atuais...\")\n",
    "dfs_pred = {}\n",
    "\n",
    "for T in CONFIG['horizons']:\n",
    "    pred_file = preds_dir / f'preds_T={T}.parquet'\n",
    "    if pred_file.exists():\n",
    "        df_temp = pd.read_parquet(pred_file)\n",
    "        df_temp['ts0'] = pd.to_datetime(df_temp['ts0'], utc=True)\n",
    "        if 'ts_forecast' in df_temp.columns:\n",
    "            df_temp['ts_forecast'] = pd.to_datetime(df_temp['ts_forecast'], utc=True)\n",
    "        dfs_pred[T] = df_temp\n",
    "        print(f\"   ✓ T={T}: {len(df_temp)} predições\")\n",
    "    else:\n",
    "        print(f\"   ⚠️  T={T}: arquivo não encontrado\")\n",
    "\n",
    "print(f\"\\n✅ {len(dfs_pred)} arquivos de predição carregados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d75bf9e",
   "metadata": {},
   "source": [
    "## 3. Geração de Previsões para Backtest (Pseudo-Backtest)\n",
    "\n",
    "Vamos selecionar N pontos temporais históricos e gerar previsões para cada um,\n",
    "simulando como seriam as previsões se tivéssemos feito naquele momento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2839398f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Selecionando pontos ts0 para backtest:\n",
      "   • Total de pontos: 50\n",
      "   • Primeiro ts0: 2025-09-11 20:00:00\n",
      "   • Último ts0: 2025-09-20 00:00:00\n",
      "   • Data máxima features: 2025-10-02 00:00:00+00:00\n",
      "   • Buffer para forecasts: 12 dias\n",
      "   • Horizonte máximo: 10.0 dias\n"
     ]
    }
   ],
   "source": [
    "# Selecionar pontos ts0 para backtest\n",
    "# Vamos pegar os últimos N pontos, mas deixando espaço para as previsões se realizarem\n",
    "max_horizon_days = max(CONFIG['horizons']) * CONFIG['bar_frequency_hours'] / 24\n",
    "buffer_days = int(max_horizon_days) + 2  # Margem de segurança\n",
    "\n",
    "# Data máxima possível para ts0 (deixar espaço para forecast se realizar)\n",
    "max_ts0 = df_features['ts'].max() - pd.Timedelta(days=buffer_days)\n",
    "\n",
    "# Filtrar features até max_ts0\n",
    "df_features_backtest = df_features[df_features['ts'] <= max_ts0].copy()\n",
    "\n",
    "# Selecionar últimos N pontos\n",
    "n_points = min(CONFIG['n_backtest_points'], len(df_features_backtest))\n",
    "backtest_indices = np.linspace(\n",
    "    len(df_features_backtest) - n_points,\n",
    "    len(df_features_backtest) - 1,\n",
    "    n_points,\n",
    "    dtype=int\n",
    ")\n",
    "\n",
    "ts0_points = df_features_backtest.iloc[backtest_indices]['ts'].values\n",
    "\n",
    "print(f\"🎯 Selecionando pontos ts0 para backtest:\")\n",
    "print(f\"   • Total de pontos: {n_points}\")\n",
    "print(f\"   • Primeiro ts0: {pd.Timestamp(ts0_points[0])}\")\n",
    "print(f\"   • Último ts0: {pd.Timestamp(ts0_points[-1])}\")\n",
    "print(f\"   • Data máxima features: {df_features['ts'].max()}\")\n",
    "print(f\"   • Buffer para forecasts: {buffer_days} dias\")\n",
    "print(f\"   • Horizonte máximo: {max_horizon_days:.1f} dias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb66ba54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔮 Gerando pseudo-previsões...\n",
      "⚠️  Nota: Usando modelo atual = look-ahead bias presente\n",
      "\n",
      "   Processados: 10/50 pontos ts0\n",
      "   Processados: 20/50 pontos ts0\n",
      "   Processados: 30/50 pontos ts0\n",
      "   Processados: 40/50 pontos ts0\n",
      "   Processados: 50/50 pontos ts0\n",
      "\n",
      "✅ Pseudo-previsões geradas:\n",
      "   • Total: 200 previsões\n",
      "   • Por horizonte:\n",
      "      - T=42: 50 previsões\n",
      "      - T=48: 50 previsões\n",
      "      - T=54: 50 previsões\n",
      "      - T=60: 50 previsões\n"
     ]
    }
   ],
   "source": [
    "# Gerar pseudo-previsões para cada ts0\n",
    "# Usaremos os quantis das previsões atuais como template\n",
    "# (assumindo que a distribuição seria similar)\n",
    "\n",
    "print(\"🔮 Gerando pseudo-previsões...\")\n",
    "print(\"⚠️  Nota: Usando modelo atual = look-ahead bias presente\\n\")\n",
    "\n",
    "backtest_predictions = []\n",
    "\n",
    "for idx, ts0 in enumerate(ts0_points):\n",
    "    ts0 = pd.Timestamp(ts0, tz='UTC')  # ⭐ Adicionar timezone\n",
    "    \n",
    "    # Pegar S0 (preço no momento ts0)\n",
    "    # Usar busca por proximidade em vez de igualdade exata\n",
    "    time_diffs = (df_features['ts'] - ts0).abs()\n",
    "    closest_idx = time_diffs.idxmin()\n",
    "    s0_row = df_features.loc[closest_idx]\n",
    "    S0 = s0_row['close']\n",
    "    \n",
    "    # Para cada horizonte\n",
    "    for T in CONFIG['horizons']:\n",
    "        # Calcular ts_forecast\n",
    "        ts_forecast = ts0 + pd.Timedelta(hours=T * CONFIG['bar_frequency_hours'])\n",
    "        \n",
    "        # Pegar valores realizados\n",
    "        price_realized = get_realized_price(ts_forecast, df_features, \n",
    "                                            CONFIG['tolerance_hours'])\n",
    "        \n",
    "        if price_realized is None:\n",
    "            continue  # Pular se não temos o valor realizado\n",
    "        \n",
    "        # Usar os quantis das previsões atuais como proporção de S0\n",
    "        # (isso é a simplificação do pseudo-backtest)\n",
    "        if T in dfs_pred and len(dfs_pred[T]) > 0:\n",
    "            # Pegar uma previsão recente como template\n",
    "            template = dfs_pred[T].iloc[-1]\n",
    "            \n",
    "            # Calcular quantis proporcionalmente a S0\n",
    "            ratio_05 = template['p_05'] / template['S0']\n",
    "            ratio_25 = template['p_25'] / template['S0']\n",
    "            ratio_50 = template['p_50'] / template['S0']\n",
    "            ratio_75 = template['p_75'] / template['S0']\n",
    "            ratio_95 = template['p_95'] / template['S0']\n",
    "            \n",
    "            backtest_predictions.append({\n",
    "                'ts0': ts0,\n",
    "                'T': T,\n",
    "                'ts_forecast': ts_forecast,\n",
    "                'S0': S0,\n",
    "                'p_05': S0 * ratio_05,\n",
    "                'p_25': S0 * ratio_25,\n",
    "                'p_50': S0 * ratio_50,\n",
    "                'p_75': S0 * ratio_75,\n",
    "                'p_95': S0 * ratio_95,\n",
    "                'price_realized': price_realized,\n",
    "                'days_ahead': T * CONFIG['bar_frequency_hours'] / 24,\n",
    "            })\n",
    "    \n",
    "    if (idx + 1) % 10 == 0:\n",
    "        print(f\"   Processados: {idx + 1}/{n_points} pontos ts0\")\n",
    "\n",
    "# Criar DataFrame\n",
    "df_backtest = pd.DataFrame(backtest_predictions)\n",
    "\n",
    "print(f\"\\n✅ Pseudo-previsões geradas:\")\n",
    "print(f\"   • Total: {len(df_backtest)} previsões\")\n",
    "if len(df_backtest) > 0:\n",
    "    print(f\"   • Por horizonte:\")\n",
    "    for T in CONFIG['horizons']:\n",
    "        count = len(df_backtest[df_backtest['T'] == T])\n",
    "        print(f\"      - T={T}: {count} previsões\")\n",
    "else:\n",
    "    print(\"   ⚠️  Nenhuma previsão gerada! Verifique os dados.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04d6e623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 DEBUG: Verificando geração de previsões...\n",
      "\n",
      "Testando com ts0=2025-09-11 20:00:00\n",
      "Linhas com ts0: 0\n"
     ]
    }
   ],
   "source": [
    "# Debug: Verificar por que não temos previsões\n",
    "print(\"🔍 DEBUG: Verificando geração de previsões...\")\n",
    "\n",
    "test_ts0 = pd.Timestamp(ts0_points[0])\n",
    "print(f\"\\nTestando com ts0={test_ts0}\")\n",
    "\n",
    "# Verificar S0\n",
    "s0_row = df_features[df_features['ts'] == test_ts0]\n",
    "print(f\"Linhas com ts0: {len(s0_row)}\")\n",
    "if len(s0_row) > 0:\n",
    "    S0 = s0_row.iloc[0]['close']\n",
    "    print(f\"S0: ${S0:,.2f}\")\n",
    "    \n",
    "    # Testar um horizonte\n",
    "    T = 42\n",
    "    ts_forecast = test_ts0 + pd.Timedelta(hours=T * CONFIG['bar_frequency_hours'])\n",
    "    print(f\"\\nT={T}, ts_forecast={ts_forecast}\")\n",
    "    \n",
    "    # Testar get_realized_price\n",
    "    price_realized = get_realized_price(ts_forecast, df_features, CONFIG['tolerance_hours'])\n",
    "    print(f\"Price realized: {price_realized}\")\n",
    "    \n",
    "    if price_realized:\n",
    "        print(\"✅ Conseguiu pegar preço realizado\")\n",
    "    else:\n",
    "        print(\"❌ Não conseguiu pegar preço realizado\")\n",
    "        \n",
    "        # Ver qual é o timestamp mais próximo\n",
    "        df_features_temp = df_features.copy()\n",
    "        df_features_temp['time_diff'] = (df_features_temp['ts'] - ts_forecast).abs()\n",
    "        closest = df_features_temp.nsmallest(5, 'time_diff')[['ts', 'close', 'time_diff']]\n",
    "        print(\"\\nTimestamps mais próximos:\")\n",
    "        print(closest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340f96d5",
   "metadata": {},
   "source": [
    "## 4. Construção das Faixas Compostas\n",
    "\n",
    "Para cada data futura, selecionamos a previsão do modelo com horizonte específico para aquela data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f335b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎨 Construindo faixas compostas...\n",
      "   ✓ Total de previsões compostas: 200\n",
      "   ✓ Período: 2025-09-11 20:00:00+00:00 a 2025-09-20 00:00:00+00:00\n",
      "   ✓ Forecast dates: 2025-09-18 20:00:00+00:00 a 2025-09-30 00:00:00+00:00\n"
     ]
    }
   ],
   "source": [
    "# Para faixas compostas, cada ts_forecast deve usar a previsão do horizonte correto\n",
    "# Precisamos agrupar por ts_forecast e pegar apenas a previsão \"nativa\" daquela data\n",
    "\n",
    "print(\"🎨 Construindo faixas compostas...\")\n",
    "\n",
    "# Criar mapeamento: ts_forecast → horizonte esperado\n",
    "# Para cada ts0, calculamos qual T corresponde a cada data futura\n",
    "\n",
    "composite_forecasts = []\n",
    "\n",
    "# Agrupar por ts0\n",
    "for ts0 in df_backtest['ts0'].unique():\n",
    "    ts0_preds = df_backtest[df_backtest['ts0'] == ts0]\n",
    "    \n",
    "    # Para cada horizonte, essa é a previsão \"nativa\" para aquela data específica\n",
    "    for T in CONFIG['horizons']:\n",
    "        t_pred = ts0_preds[ts0_preds['T'] == T]\n",
    "        if len(t_pred) > 0:\n",
    "            composite_forecasts.append(t_pred.iloc[0].to_dict())\n",
    "\n",
    "df_composite = pd.DataFrame(composite_forecasts)\n",
    "\n",
    "print(f\"   ✓ Total de previsões compostas: {len(df_composite)}\")\n",
    "print(f\"   ✓ Período: {df_composite['ts0'].min()} a {df_composite['ts0'].max()}\")\n",
    "print(f\"   ✓ Forecast dates: {df_composite['ts_forecast'].min()} a {df_composite['ts_forecast'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0f4146",
   "metadata": {},
   "source": [
    "## 5. Métricas de Calibração\n",
    "\n",
    "Avaliar se os intervalos de confiança estão bem calibrados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32025fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 MÉTRICAS DE CALIBRAÇÃO - FAIXAS COMPOSTAS\n",
      "==========================================================================================\n",
      "\n",
      "🎯 COVERAGE (Cobertura dos Intervalos):\n",
      "   • 90% CI (p05-p95): 38.50% (esperado: ~90%)\n",
      "      ⚠️  Subestimado\n",
      "   • 50% CI (p25-p75): 13.50% (esperado: ~50%)\n",
      "      ⚠️  Subestimado\n",
      "\n",
      "📏 SHARPNESS (Largura das Faixas):\n",
      "   • 90% CI: 6.40%\n",
      "   • 50% CI: 2.95%\n",
      "\n",
      "📉 ERROS DA MEDIANA (p50):\n",
      "   • MAE:  $5,207.12\n",
      "   • MAPE: 4.68%\n",
      "   • RMSE: $5,946.58\n",
      "   • Bias: $5,140.43 (otimista)\n",
      "\n",
      "🎲 PINBALL LOSS (Qualidade dos Quantis):\n",
      "   • p05: 1666.67\n",
      "   • p25: 2711.85\n",
      "   • p50: 2603.56 (menor é melhor)\n",
      "   • p75: 1710.82\n",
      "   • p95: 422.09\n",
      "\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"📊 MÉTRICAS DE CALIBRAÇÃO - FAIXAS COMPOSTAS\")\n",
    "print(\"=\"*90)\n",
    "\n",
    "# Extrair arrays\n",
    "y_true = df_composite['price_realized'].values\n",
    "y_p05 = df_composite['p_05'].values\n",
    "y_p25 = df_composite['p_25'].values\n",
    "y_p50 = df_composite['p_50'].values\n",
    "y_p75 = df_composite['p_75'].values\n",
    "y_p95 = df_composite['p_95'].values\n",
    "S0 = df_composite['S0'].values\n",
    "\n",
    "# 1. Coverage dos intervalos de confiança\n",
    "coverage_90 = calculate_coverage(y_true, y_p05, y_p95)\n",
    "coverage_50 = calculate_coverage(y_true, y_p25, y_p75)\n",
    "\n",
    "print(f\"\\n🎯 COVERAGE (Cobertura dos Intervalos):\")\n",
    "print(f\"   • 90% CI (p05-p95): {coverage_90:.2f}% (esperado: ~90%)\")\n",
    "if 85 <= coverage_90 <= 95:\n",
    "    print(f\"      ✅ Bem calibrado!\")\n",
    "else:\n",
    "    print(f\"      ⚠️  {'Subestimado' if coverage_90 < 85 else 'Superestimado'}\")\n",
    "\n",
    "print(f\"   • 50% CI (p25-p75): {coverage_50:.2f}% (esperado: ~50%)\")\n",
    "if 45 <= coverage_50 <= 55:\n",
    "    print(f\"      ✅ Bem calibrado!\")\n",
    "else:\n",
    "    print(f\"      ⚠️  {'Subestimado' if coverage_50 < 45 else 'Superestimado'}\")\n",
    "\n",
    "# 2. Sharpness (largura das faixas)\n",
    "sharpness_90 = calculate_sharpness(y_p05, y_p95, S0)\n",
    "sharpness_50 = calculate_sharpness(y_p25, y_p75, S0)\n",
    "\n",
    "print(f\"\\n📏 SHARPNESS (Largura das Faixas):\")\n",
    "print(f\"   • 90% CI: {sharpness_90:.2f}%\")\n",
    "print(f\"   • 50% CI: {sharpness_50:.2f}%\")\n",
    "\n",
    "# 3. Erros da mediana (p50)\n",
    "mae = np.mean(np.abs(y_true - y_p50))\n",
    "mape = np.mean(np.abs(y_true - y_p50) / y_true) * 100\n",
    "rmse = np.sqrt(np.mean((y_true - y_p50)**2))\n",
    "bias = np.mean(y_p50 - y_true)\n",
    "\n",
    "print(f\"\\n📉 ERROS DA MEDIANA (p50):\")\n",
    "print(f\"   • MAE:  ${mae:,.2f}\")\n",
    "print(f\"   • MAPE: {mape:.2f}%\")\n",
    "print(f\"   • RMSE: ${rmse:,.2f}\")\n",
    "print(f\"   • Bias: ${bias:,.2f} ({'otimista' if bias > 0 else 'pessimista'})\")\n",
    "\n",
    "# 4. Pinball Loss por quantil\n",
    "loss_05 = pinball_loss(y_true, y_p05, 0.05)\n",
    "loss_25 = pinball_loss(y_true, y_p25, 0.25)\n",
    "loss_50 = pinball_loss(y_true, y_p50, 0.50)\n",
    "loss_75 = pinball_loss(y_true, y_p75, 0.75)\n",
    "loss_95 = pinball_loss(y_true, y_p95, 0.95)\n",
    "\n",
    "print(f\"\\n🎲 PINBALL LOSS (Qualidade dos Quantis):\")\n",
    "print(f\"   • p05: {loss_05:.2f}\")\n",
    "print(f\"   • p25: {loss_25:.2f}\")\n",
    "print(f\"   • p50: {loss_50:.2f} (menor é melhor)\")\n",
    "print(f\"   • p75: {loss_75:.2f}\")\n",
    "print(f\"   • p95: {loss_95:.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0cbf7a",
   "metadata": {},
   "source": [
    "### Métricas por Horizonte\n",
    "\n",
    "Comparar a performance de cada horizonte individual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e45ee557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 MÉTRICAS POR HORIZONTE\n",
      "==========================================================================================\n",
      " Horizonte  N Cov 90% Cov 50% Largura 90% Largura 50%    MAE  MAPE\n",
      " T=42 (7d) 50   64.0%   10.0%       4.82%       1.19% $3,542 3.17%\n",
      " T=48 (8d) 50   46.0%   28.0%       7.41%       5.39% $6,641 5.95%\n",
      " T=54 (9d) 50   20.0%   14.0%       7.75%       3.94% $4,550 4.11%\n",
      "T=60 (10d) 50   24.0%    2.0%       5.64%       1.28% $6,095 5.49%\n",
      "\\n==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"📊 MÉTRICAS POR HORIZONTE\")\n",
    "print(\"=\"*90)\n",
    "\n",
    "metrics_by_horizon = []\n",
    "\n",
    "for T in CONFIG['horizons']:\n",
    "    df_T = df_composite[df_composite['T'] == T]\n",
    "    \n",
    "    if len(df_T) == 0:\n",
    "        continue\n",
    "    \n",
    "    y_true_T = df_T['price_realized'].values\n",
    "    y_p05_T = df_T['p_05'].values\n",
    "    y_p25_T = df_T['p_25'].values\n",
    "    y_p50_T = df_T['p_50'].values\n",
    "    y_p75_T = df_T['p_75'].values\n",
    "    y_p95_T = df_T['p_95'].values\n",
    "    S0_T = df_T['S0'].values\n",
    "    \n",
    "    coverage_90_T = calculate_coverage(y_true_T, y_p05_T, y_p95_T)\n",
    "    coverage_50_T = calculate_coverage(y_true_T, y_p25_T, y_p75_T)\n",
    "    sharpness_90_T = calculate_sharpness(y_p05_T, y_p95_T, S0_T)\n",
    "    sharpness_50_T = calculate_sharpness(y_p25_T, y_p75_T, S0_T)\n",
    "    mae_T = np.mean(np.abs(y_true_T - y_p50_T))\n",
    "    mape_T = np.mean(np.abs(y_true_T - y_p50_T) / y_true_T) * 100\n",
    "    \n",
    "    days_ahead = T * CONFIG['bar_frequency_hours'] / 24\n",
    "    \n",
    "    metrics_by_horizon.append({\n",
    "        'Horizonte': f'T={T} ({days_ahead:.0f}d)',\n",
    "        'N': len(df_T),\n",
    "        'Cov 90%': f'{coverage_90_T:.1f}%',\n",
    "        'Cov 50%': f'{coverage_50_T:.1f}%',\n",
    "        'Largura 90%': f'{sharpness_90_T:.2f}%',\n",
    "        'Largura 50%': f'{sharpness_50_T:.2f}%',\n",
    "        'MAE': f'${mae_T:,.0f}',\n",
    "        'MAPE': f'{mape_T:.2f}%',\n",
    "    })\n",
    "\n",
    "df_metrics_horizon = pd.DataFrame(metrics_by_horizon)\n",
    "print(df_metrics_horizon.to_string(index=False))\n",
    "print(\"\\\\n\" + \"=\"*90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c70abcb",
   "metadata": {},
   "source": [
    "## 🚨 Análise Crítica: Os Resultados São Preocupantes?\n",
    "\n",
    "Vamos interpretar os resultados com contexto adequado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6e56b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 ANÁLISE CONTEXTUAL DOS RESULTADOS\n",
      "==========================================================================================\n",
      "\n",
      "📅 1. CONTEXTO TEMPORAL\n",
      "------------------------------------------------------------------------------------------\n",
      "Período de previsão: 2025-09-11 a 2025-09-30\n",
      "Preço inicial: $114,442.51\n",
      "Preço final: $114,613.54\n",
      "Variação: +0.15%\n",
      "\n",
      "➡️  Movimento lateral no período.\n",
      "\n",
      "\n",
      "📊 2. DISTRIBUIÇÃO DOS ERROS\n",
      "------------------------------------------------------------------------------------------\n",
      "Erro médio: $-5,140.43 (-4.62%)\n",
      "Erro mediano: $-4,961.37 (-4.44%)\n",
      "Erro std: $2,989.62\n",
      "Erro mín: $-11,512.87 (modelo subestimou)\n",
      "Erro máx: $2,351.45 (modelo superestimou)\n",
      "\n",
      "📈 Modelo previu acima do real: 96.0% das vezes\n",
      "📉 Modelo previu abaixo do real: 4.0% das vezes\n",
      "   ⚠️  VIÉS SISTEMÁTICO: Modelo é muito otimista!\n",
      "\n",
      "\n",
      "🎯 3. CALIBRAÇÃO EM PERSPECTIVA\n",
      "------------------------------------------------------------------------------------------\n",
      "Coverage 90% observado: 38.5%\n",
      "Coverage ideal: 90%\n",
      "Diferença: -51.5 pontos percentuais\n",
      "\n",
      "❌ PROBLEMA SÉRIO: Faixas MUITO estreitas\n",
      "   • As previsões não capturam a volatilidade real\n",
      "   • Confiança excessiva nas estimativas\n",
      "   • Risco de decisões baseadas em intervalos irrealistas\n",
      "\n",
      "\n",
      "📏 4. COMPARAÇÃO COM BENCHMARKS\n",
      "------------------------------------------------------------------------------------------\n",
      "MAPE: 4.68%\n",
      "   ✅ Bom (3-5%)\n",
      "\n",
      "Sharpness 90% CI: 6.40%\n",
      "   ✅ Razoável (5-10%)\n",
      "\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"🔍 ANÁLISE CONTEXTUAL DOS RESULTADOS\")\n",
    "print(\"=\"*90)\n",
    "\n",
    "# 1. Analisar o período testado\n",
    "print(\"\\n📅 1. CONTEXTO TEMPORAL\")\n",
    "print(\"-\"*90)\n",
    "\n",
    "# Verificar movimento de preços no período\n",
    "ts0_min = df_composite['ts0'].min()\n",
    "ts0_max = df_composite['ts0'].max()\n",
    "ts_forecast_min = df_composite['ts_forecast'].min()\n",
    "ts_forecast_max = df_composite['ts_forecast'].max()\n",
    "\n",
    "# Pegar preços do período\n",
    "prices_start = df_features[df_features['ts'] >= ts0_min]['close'].iloc[0] if len(df_features[df_features['ts'] >= ts0_min]) > 0 else None\n",
    "prices_end = df_features[df_features['ts'] <= ts_forecast_max].iloc[-1]['close'] if len(df_features[df_features['ts'] <= ts_forecast_max]) > 0 else None\n",
    "\n",
    "if prices_start and prices_end:\n",
    "    price_change = (prices_end - prices_start) / prices_start * 100\n",
    "    print(f\"Período de previsão: {ts0_min.strftime('%Y-%m-%d')} a {ts_forecast_max.strftime('%Y-%m-%d')}\")\n",
    "    print(f\"Preço inicial: ${prices_start:,.2f}\")\n",
    "    print(f\"Preço final: ${prices_end:,.2f}\")\n",
    "    print(f\"Variação: {price_change:+.2f}%\")\n",
    "    \n",
    "    if price_change < -5:\n",
    "        print(f\"\\n⚠️  QUEDA SIGNIFICATIVA no período testado!\")\n",
    "        print(f\"   Isso explica o bias otimista do modelo.\")\n",
    "    elif price_change > 5:\n",
    "        print(f\"\\n📈 ALTA SIGNIFICATIVA no período testado.\")\n",
    "    else:\n",
    "        print(f\"\\n➡️  Movimento lateral no período.\")\n",
    "\n",
    "# 2. Comparar previsões vs realidade\n",
    "print(\"\\n\\n📊 2. DISTRIBUIÇÃO DOS ERROS\")\n",
    "print(\"-\"*90)\n",
    "\n",
    "errors = y_true - y_p50\n",
    "errors_pct = (y_true - y_p50) / y_true * 100\n",
    "\n",
    "print(f\"Erro médio: ${np.mean(errors):,.2f} ({np.mean(errors_pct):.2f}%)\")\n",
    "print(f\"Erro mediano: ${np.median(errors):,.2f} ({np.median(errors_pct):.2f}%)\")\n",
    "print(f\"Erro std: ${np.std(errors):,.2f}\")\n",
    "print(f\"Erro mín: ${np.min(errors):,.2f} (modelo subestimou)\")\n",
    "print(f\"Erro máx: ${np.max(errors):,.2f} (modelo superestimou)\")\n",
    "\n",
    "# Percentual de vezes que errou para cima vs para baixo\n",
    "overestimated = np.sum(y_p50 > y_true) / len(y_true) * 100\n",
    "underestimated = np.sum(y_p50 < y_true) / len(y_true) * 100\n",
    "\n",
    "print(f\"\\n📈 Modelo previu acima do real: {overestimated:.1f}% das vezes\")\n",
    "print(f\"📉 Modelo previu abaixo do real: {underestimated:.1f}% das vezes\")\n",
    "\n",
    "if overestimated > 70:\n",
    "    print(f\"   ⚠️  VIÉS SISTEMÁTICO: Modelo é muito otimista!\")\n",
    "elif underestimated > 70:\n",
    "    print(f\"   ⚠️  VIÉS SISTEMÁTICO: Modelo é muito pessimista!\")\n",
    "\n",
    "# 3. Análise de calibração por contexto\n",
    "print(\"\\n\\n🎯 3. CALIBRAÇÃO EM PERSPECTIVA\")\n",
    "print(\"-\"*90)\n",
    "\n",
    "print(f\"Coverage 90% observado: {coverage_90:.1f}%\")\n",
    "print(f\"Coverage ideal: 90%\")\n",
    "print(f\"Diferença: {coverage_90 - 90:.1f} pontos percentuais\")\n",
    "\n",
    "if coverage_90 < 50:\n",
    "    print(f\"\\n❌ PROBLEMA SÉRIO: Faixas MUITO estreitas\")\n",
    "    print(f\"   • As previsões não capturam a volatilidade real\")\n",
    "    print(f\"   • Confiança excessiva nas estimativas\")\n",
    "    print(f\"   • Risco de decisões baseadas em intervalos irrealistas\")\n",
    "elif coverage_90 < 75:\n",
    "    print(f\"\\n⚠️  PROBLEMA MODERADO: Faixas subestimadas\")\n",
    "    print(f\"   • Incerteza real é maior que o modelo indica\")\n",
    "    print(f\"   • Requer ajuste na calibração\")\n",
    "elif coverage_90 < 85:\n",
    "    print(f\"\\n⚙️  Pequeno desvio: Calibração precisa de ajuste fino\")\n",
    "else:\n",
    "    print(f\"\\n✅ Calibração aceitável (85-95%)\")\n",
    "\n",
    "# 4. Comparação com benchmarks\n",
    "print(\"\\n\\n📏 4. COMPARAÇÃO COM BENCHMARKS\")\n",
    "print(\"-\"*90)\n",
    "\n",
    "print(f\"MAPE: {mape:.2f}%\")\n",
    "if mape < 3:\n",
    "    print(f\"   ✅ Excelente (< 3%)\")\n",
    "elif mape < 5:\n",
    "    print(f\"   ✅ Bom (3-5%)\")\n",
    "elif mape < 10:\n",
    "    print(f\"   ⚠️  Aceitável (5-10%) - Pode melhorar\")\n",
    "else:\n",
    "    print(f\"   ❌ Ruim (> 10%) - Necessita revisão\")\n",
    "\n",
    "print(f\"\\nSharpness 90% CI: {sharpness_90:.2f}%\")\n",
    "if sharpness_90 < 5:\n",
    "    print(f\"   ⚠️  Faixas muito estreitas (< 5%)\")\n",
    "    print(f\"   Risco: Falsa sensação de precisão\")\n",
    "elif sharpness_90 < 10:\n",
    "    print(f\"   ✅ Razoável (5-10%)\")\n",
    "elif sharpness_90 < 20:\n",
    "    print(f\"   ⚠️  Faixas largas (10-20%)\")\n",
    "    print(f\"   Trade-off: Mais cautela, menos informativo\")\n",
    "else:\n",
    "    print(f\"   ❌ Faixas muito largas (> 20%)\")\n",
    "    print(f\"   Utilidade questionável\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f232de60",
   "metadata": {},
   "source": [
    "## ⚖️ VEREDITO FINAL: É Preocupante?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd82c101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚖️ VEREDITO FINAL: OS RESULTADOS SÃO PREOCUPANTES?\n",
      "==========================================================================================\n",
      "\n",
      "🎯 RESUMO EXECUTIVO:\n",
      "\n",
      "🚨 PROBLEMAS CRÍTICOS:\n",
      "   ❌ Coverage MUITO baixo (38.5% vs 90% esperado)\n",
      "   ❌ Faixas de confiança extremamente subestimadas\n",
      "   ❌ Viés sistemático SEVERO (96% prevê acima)\n",
      "\n",
      "✅ PONTOS POSITIVOS:\n",
      "   ✅ MAPE excelente (4.68%)\n",
      "   ✅ Largura das faixas razoável (6.40%)\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "💡 INTERPRETAÇÃO GERAL:\n",
      "\n",
      "🔴 SIM, OS RESULTADOS SÃO PREOCUPANTES\n",
      "\n",
      "   O modelo apresenta problemas significativos:\n",
      "\n",
      "   1️⃣  VIÉS OTIMISTA SISTEMÁTICO\n",
      "      • 96% das previsões acima do real\n",
      "      • Bias médio de +$5,140 (4.6%)\n",
      "      • Modelo 'espera' preços mais altos que a realidade\n",
      "\n",
      "   2️⃣  INTERVALO DE CONFIANÇA MAL CALIBRADO\n",
      "      • Coverage de 38.5% quando deveria ser 90%\n",
      "      • Faixas muito estreitas (overconfident)\n",
      "      • Subestima a incerteza real do mercado\n",
      "\n",
      "   ⚠️  IMPLICAÇÕES PRÁTICAS:\n",
      "      • Trading: Estratégias podem ser muito agressivas\n",
      "      • Risk Management: Subestimação de riscos\n",
      "      • Stop-loss: Pode ser acionado com frequência inesperada\n",
      "\n",
      "\n",
      "==========================================================================================\n",
      "\n",
      "📋 RECOMENDAÇÕES:\n",
      "\n",
      "1️⃣  CURTO PRAZO (Usar modelo hoje):\n",
      "   • ⚠️  Ajustar expectativas: Reduzir previsões em ~4-5%\n",
      "   • ⚠️  Ampliar faixas: Multiplicar p05/p95 por fator 1.5-2.0\n",
      "   • ✅ Usar MAPE como referência de erro esperado\n",
      "\n",
      "2️⃣  MÉDIO PRAZO (Melhorias no modelo):\n",
      "   • 🔧 Recalibrar quantis (ajustar alpha/conformidade)\n",
      "   • 🔧 Investigar período de treinamento (pode estar enviesado)\n",
      "   • 🔧 Adicionar features de volatilidade/regime de mercado\n",
      "   • 🔧 Testar com períodos mais longos de backtest\n",
      "\n",
      "3️⃣  LONGO PRAZO (Validação):\n",
      "   • 📊 Walk-forward backtest (re-treinar no passado)\n",
      "   • 📊 Validação out-of-sample real (dados nunca vistos)\n",
      "   • 📊 Comparar com benchmarks (naive, GARCH, etc)\n",
      "\n",
      "==========================================================================================\n",
      "\n",
      "⚡ NOTA IMPORTANTE SOBRE PSEUDO-BACKTEST:\n",
      "\n",
      "   Estes resultados têm LOOK-AHEAD BIAS (modelo viu os dados).\n",
      "   Em um backtest real (walk-forward), os resultados podem ser:\n",
      "   • 📉 PIORES: Se o modelo se beneficiou do look-ahead\n",
      "   • 📈 MELHORES: Se o período testado foi atipicamente difícil\n",
      "\n",
      "   Para conclusões definitivas, NECESSÁRIO fazer walk-forward backtest.\n",
      "\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"⚖️ VEREDITO FINAL: OS RESULTADOS SÃO PREOCUPANTES?\")\n",
    "print(\"=\"*90)\n",
    "\n",
    "print(\"\\n🎯 RESUMO EXECUTIVO:\\n\")\n",
    "\n",
    "# Identificar problemas\n",
    "problems = []\n",
    "warnings = []\n",
    "positives = []\n",
    "\n",
    "# Avaliar cada aspecto\n",
    "if coverage_90 < 50:\n",
    "    problems.append(\"❌ Coverage MUITO baixo (38.5% vs 90% esperado)\")\n",
    "    problems.append(\"❌ Faixas de confiança extremamente subestimadas\")\n",
    "elif coverage_90 < 75:\n",
    "    warnings.append(\"⚠️  Coverage baixo - faixas subestimadas\")\n",
    "\n",
    "if overestimated > 90:\n",
    "    problems.append(f\"❌ Viés sistemático SEVERO ({overestimated:.0f}% prevê acima)\")\n",
    "elif overestimated > 70:\n",
    "    warnings.append(f\"⚠️  Viés sistemático moderado ({overestimated:.0f}% prevê acima)\")\n",
    "\n",
    "if mape < 5:\n",
    "    positives.append(f\"✅ MAPE excelente ({mape:.2f}%)\")\n",
    "elif mape < 10:\n",
    "    positives.append(f\"✅ MAPE aceitável ({mape:.2f}%)\")\n",
    "else:\n",
    "    problems.append(f\"❌ MAPE ruim ({mape:.2f}%)\")\n",
    "\n",
    "if 5 <= sharpness_90 <= 10:\n",
    "    positives.append(f\"✅ Largura das faixas razoável ({sharpness_90:.2f}%)\")\n",
    "\n",
    "# Mostrar resultados\n",
    "if problems:\n",
    "    print(\"🚨 PROBLEMAS CRÍTICOS:\")\n",
    "    for p in problems:\n",
    "        print(f\"   {p}\")\n",
    "    print()\n",
    "\n",
    "if warnings:\n",
    "    print(\"⚠️  PONTOS DE ATENÇÃO:\")\n",
    "    for w in warnings:\n",
    "        print(f\"   {w}\")\n",
    "    print()\n",
    "\n",
    "if positives:\n",
    "    print(\"✅ PONTOS POSITIVOS:\")\n",
    "    for p in positives:\n",
    "        print(f\"   {p}\")\n",
    "    print()\n",
    "\n",
    "# Veredito geral\n",
    "print(\"-\"*90)\n",
    "print(\"\\n💡 INTERPRETAÇÃO GERAL:\\n\")\n",
    "\n",
    "if len(problems) >= 2:\n",
    "    print(\"🔴 SIM, OS RESULTADOS SÃO PREOCUPANTES\")\n",
    "    print()\n",
    "    print(\"   O modelo apresenta problemas significativos:\")\n",
    "    print()\n",
    "    print(\"   1️⃣  VIÉS OTIMISTA SISTEMÁTICO\")\n",
    "    print(\"      • 96% das previsões acima do real\")\n",
    "    print(\"      • Bias médio de +$5,140 (4.6%)\")\n",
    "    print(\"      • Modelo 'espera' preços mais altos que a realidade\")\n",
    "    print()\n",
    "    print(\"   2️⃣  INTERVALO DE CONFIANÇA MAL CALIBRADO\")\n",
    "    print(\"      • Coverage de 38.5% quando deveria ser 90%\")\n",
    "    print(\"      • Faixas muito estreitas (overconfident)\")\n",
    "    print(\"      • Subestima a incerteza real do mercado\")\n",
    "    print()\n",
    "    print(\"   ⚠️  IMPLICAÇÕES PRÁTICAS:\")\n",
    "    print(\"      • Trading: Estratégias podem ser muito agressivas\")\n",
    "    print(\"      • Risk Management: Subestimação de riscos\")\n",
    "    print(\"      • Stop-loss: Pode ser acionado com frequência inesperada\")\n",
    "    print()\n",
    "else:\n",
    "    print(\"🟡 RESULTADOS MISTOS - REQUER ATENÇÃO\")\n",
    "    print()\n",
    "    print(\"   O modelo tem aspectos bons e ruins:\")\n",
    "    print(\"   ✅ Erro médio (MAPE) aceitável\")\n",
    "    print(\"   ❌ Calibração dos intervalos precisa melhorar\")\n",
    "    print()\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print()\n",
    "print(\"📋 RECOMENDAÇÕES:\")\n",
    "print()\n",
    "print(\"1️⃣  CURTO PRAZO (Usar modelo hoje):\")\n",
    "print(\"   • ⚠️  Ajustar expectativas: Reduzir previsões em ~4-5%\")\n",
    "print(\"   • ⚠️  Ampliar faixas: Multiplicar p05/p95 por fator 1.5-2.0\")\n",
    "print(\"   • ✅ Usar MAPE como referência de erro esperado\")\n",
    "print()\n",
    "print(\"2️⃣  MÉDIO PRAZO (Melhorias no modelo):\")\n",
    "print(\"   • 🔧 Recalibrar quantis (ajustar alpha/conformidade)\")\n",
    "print(\"   • 🔧 Investigar período de treinamento (pode estar enviesado)\")\n",
    "print(\"   • 🔧 Adicionar features de volatilidade/regime de mercado\")\n",
    "print(\"   • 🔧 Testar com períodos mais longos de backtest\")\n",
    "print()\n",
    "print(\"3️⃣  LONGO PRAZO (Validação):\")\n",
    "print(\"   • 📊 Walk-forward backtest (re-treinar no passado)\")\n",
    "print(\"   • 📊 Validação out-of-sample real (dados nunca vistos)\")\n",
    "print(\"   • 📊 Comparar com benchmarks (naive, GARCH, etc)\")\n",
    "print()\n",
    "print(\"=\"*90)\n",
    "print()\n",
    "print(\"⚡ NOTA IMPORTANTE SOBRE PSEUDO-BACKTEST:\")\n",
    "print()\n",
    "print(\"   Estes resultados têm LOOK-AHEAD BIAS (modelo viu os dados).\")\n",
    "print(\"   Em um backtest real (walk-forward), os resultados podem ser:\")\n",
    "print(\"   • 📉 PIORES: Se o modelo se beneficiou do look-ahead\")\n",
    "print(\"   • 📈 MELHORES: Se o período testado foi atipicamente difícil\")\n",
    "print()\n",
    "print(\"   Para conclusões definitivas, NECESSÁRIO fazer walk-forward backtest.\")\n",
    "print()\n",
    "print(\"=\"*90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae6af15",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 📝 Resposta Direta: Os Resultados São Preocupantes?\n",
    "\n",
    "### 🔴 **SIM, são preocupantes, mas com contexto importante:**\n",
    "\n",
    "#### ❌ Problemas Identificados:\n",
    "\n",
    "1. **Viés Otimista Severo**: \n",
    "   - 96% das previsões são mais altas que a realidade\n",
    "   - Bias médio de +$5,140 (4.6%)\n",
    "   - Modelo sistematicamente \"otimista\"\n",
    "\n",
    "2. **Intervalos de Confiança Mal Calibrados**:\n",
    "   - Coverage de apenas 38.5% quando deveria ser 90%\n",
    "   - Faixas muito estreitas (\"overconfident\")\n",
    "   - Subestima a incerteza real\n",
    "\n",
    "#### ✅ Pontos Positivos:\n",
    "\n",
    "1. **Erro Médio Aceitável**:\n",
    "   - MAPE de 4.68% é considerado bom\n",
    "   - Modelo tem capacidade preditiva\n",
    "\n",
    "2. **Largura Razoável**:\n",
    "   - 6.4% de largura está dentro do aceitável\n",
    "   - O problema é a calibração, não a largura em si\n",
    "\n",
    "---\n",
    "\n",
    "### 🤔 Mas Por Que Isso Aconteceu?\n",
    "\n",
    "Possíveis causas:\n",
    "\n",
    "1. **Período de Treinamento Otimista**:\n",
    "   - Modelo treinado em período de alta\n",
    "   - \"Aprendeu\" a esperar preços crescentes\n",
    "\n",
    "2. **Conformal Prediction Needs Recalibration**:\n",
    "   - Alpha atual não está capturando a distribuição real\n",
    "   - Precisa ajustar parâmetros de calibração\n",
    "\n",
    "3. **Look-Ahead Bias do Pseudo-Backtest**:\n",
    "   - Modelo viu os dados que está \"prevendo\"\n",
    "   - Resultados reais podem ser diferentes\n",
    "\n",
    "4. **Falta de Features de Regime**:\n",
    "   - Modelo não detecta mudanças de bull→bear\n",
    "   - Sempre assume regime similar ao treinamento\n",
    "\n",
    "---\n",
    "\n",
    "### 🎯 O Que Fazer?\n",
    "\n",
    "#### Solução Imediata (usar modelo hoje):\n",
    "\n",
    "```python\n",
    "# Ajustar previsões\n",
    "p50_ajustado = p50_original * 0.955  # Reduzir 4.5%\n",
    "\n",
    "# Ampliar faixas\n",
    "p05_ajustado = S0 + (p05_original - S0) * 1.7\n",
    "p95_ajustado = S0 + (p95_original - S0) * 1.7\n",
    "```\n",
    "\n",
    "#### Solução de Médio Prazo:\n",
    "\n",
    "1. **Recalibrar quantis** com conformal prediction ajustado\n",
    "2. **Adicionar features** de regime de mercado (bull/bear detection)\n",
    "3. **Testar múltiplos períodos** de backtest\n",
    "4. **Implementar walk-forward** backtest verdadeiro\n",
    "\n",
    "---\n",
    "\n",
    "### ⚠️ Conclusão:\n",
    "\n",
    "**Os resultados INDICAM problemas reais** que precisam ser endereçados, MAS:\n",
    "\n",
    "- ✅ O modelo tem capacidade preditiva (MAPE bom)\n",
    "- ⚠️ A calibração precisa ser corrigida\n",
    "- 🔍 Pseudo-backtest tem limitações (look-ahead bias)\n",
    "- 📊 Necessário validação adicional (walk-forward)\n",
    "\n",
    "**Não descarte o modelo, mas não use sem ajustes!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
