{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45e32add",
   "metadata": {},
   "source": [
    "# BTC Momentum Analysis ‚Äî Module 02 Only\n",
    "\n",
    "**Objetivo:** Produzir sinais de momentum a partir das bandas quant√≠licas do M√≥dulo 02.\n",
    "\n",
    "**Escopo:** Apenas arquivos `preds_T=*.parquet` com T ‚àà {42,48,54,60}.\n",
    "\n",
    "**Sa√≠das:**\n",
    "- S√©rie temporal de scores de momentum (dire√ß√£o/volatilidade/confian√ßa)\n",
    "- Snapshots por horizonte T\n",
    "- Gr√°ficos de an√°lise\n",
    "- Relat√≥rio HTML\n",
    "- Pr√©-checagens para M√≥dulo 03\n",
    "\n",
    "---\n",
    "\n",
    "**Data de execu√ß√£o:** October 2, 2025  \n",
    "**Timezone:** UTC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00772267",
   "metadata": {},
   "source": [
    "## 1. Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "446cbb92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Imports carregados\n",
      "üìÖ Data: 2025-10-02 15:58:53 UTC\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "import yaml\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "from scipy import stats\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configura√ß√£o de plots\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline\n",
    "\n",
    "# Seed para reprodutibilidade\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úÖ Imports carregados\")\n",
    "print(f\"üìÖ Data: {datetime.now().strftime('%Y-%m-%d %H:%M:%S UTC')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0efbefb",
   "metadata": {},
   "source": [
    "### 1.1 Configuration Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5ea9db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è  Configura√ß√£o do Notebook:\n",
      "============================================================\n",
      "lookback_days       : 180\n",
      "horizons            : [42, 48, 54, 60]\n",
      "target_T_default    : 48\n",
      "tilt_strength_hi    : 1.2\n",
      "vol_hi_pct          : 0.8\n",
      "vol_lo_pct          : 0.2\n",
      "recency_max_days    : 7\n",
      "\n",
      "üìä Pesos dos Scores:\n",
      "  directional    : {'tilt': 0.6, 'slope': 0.4}\n",
      "  volatility     : {'width_pct': 0.7, 'rv_delta': 0.3}\n",
      "  confidence     : {'consistency': 0.5, 'stability': 0.5}\n",
      "\n",
      "‚úÖ Configura√ß√£o carregada\n"
     ]
    }
   ],
   "source": [
    "# Configura√ß√£o do notebook\n",
    "CONFIG = {\n",
    "    'lookback_days': 180,           # janela para an√°lises/percentis\n",
    "    'horizons': [42, 48, 54, 60],   # horizontes de previs√£o (horas)\n",
    "    'target_T_default': 48,         # horizonte padr√£o para gr√°ficos\n",
    "    'tilt_strength_hi': 1.2,        # |tilt_ratio| > este valor => dire√ß√£o forte\n",
    "    'vol_hi_pct': 0.80,             # percentil de largura > 0.8 => vol alta\n",
    "    'vol_lo_pct': 0.20,             # percentil de largura < 0.2 => vol baixa\n",
    "    'recency_max_days': 7,          # m√°ximo de dias desde √∫ltima previs√£o\n",
    "    \n",
    "    'score_weights': {\n",
    "        'directional': {'tilt': 0.6, 'slope': 0.4},\n",
    "        'volatility': {'width_pct': 0.7, 'rv_delta': 0.3},\n",
    "        'confidence': {'consistency': 0.5, 'stability': 0.5}\n",
    "    },\n",
    "    \n",
    "    'export_paths': {\n",
    "        'ts_table': 'data/processed/momentum/momentum_timeseries.parquet',\n",
    "        'snapshot': 'data/processed/momentum/momentum_snapshot.csv',\n",
    "        'report_html': 'data/processed/momentum/momentum_report.html',\n",
    "        'charts_dir': 'data/processed/momentum/charts/'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Exibir configura√ß√£o\n",
    "print(\"‚öôÔ∏è  Configura√ß√£o do Notebook:\")\n",
    "print(\"=\" * 60)\n",
    "for key, value in CONFIG.items():\n",
    "    if key != 'score_weights' and key != 'export_paths':\n",
    "        print(f\"{key:20s}: {value}\")\n",
    "\n",
    "print(\"\\nüìä Pesos dos Scores:\")\n",
    "for score_type, weights in CONFIG['score_weights'].items():\n",
    "    print(f\"  {score_type:15s}: {weights}\")\n",
    "\n",
    "print(\"\\n‚úÖ Configura√ß√£o carregada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595fde6b",
   "metadata": {},
   "source": [
    "## 2. Data Discovery & Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981c1be6",
   "metadata": {},
   "source": [
    "### 2.1 Descoberta de Arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d206f0c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Buscando em: data/processed/preds\n",
      "üìÅ Arquivos encontrados: 1\n",
      "============================================================\n",
      "  ‚úì preds_T=42.parquet             (  0.01 MB)\n",
      "\n",
      "üìã Metadados:\n",
      "  meta_pred.json: ‚úì Encontrado\n",
      "  qc_oos.json:    ‚úó N√£o encontrado\n",
      "\n",
      "‚úÖ Descoberta conclu√≠da\n"
     ]
    }
   ],
   "source": [
    "# Descobrir arquivos de predi√ß√µes\n",
    "data_dir = Path('data/processed/preds')\n",
    "pred_files = sorted(data_dir.glob('preds_T=*.parquet'))\n",
    "\n",
    "print(f\"üîç Buscando em: {data_dir}\")\n",
    "print(f\"üìÅ Arquivos encontrados: {len(pred_files)}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if not pred_files:\n",
    "    # Tentar diret√≥rio alternativo (notebooks)\n",
    "    alt_dir = Path('notebooks/data/processed/preds')\n",
    "    pred_files = sorted(alt_dir.glob('preds_T=*.parquet'))\n",
    "    print(f\"üîç Tentando diret√≥rio alternativo: {alt_dir}\")\n",
    "    print(f\"üìÅ Arquivos encontrados: {len(pred_files)}\")\n",
    "\n",
    "if pred_files:\n",
    "    for f in pred_files:\n",
    "        size_mb = f.stat().st_size / (1024*1024)\n",
    "        print(f\"  ‚úì {f.name:30s} ({size_mb:6.2f} MB)\")\n",
    "else:\n",
    "    print(\"‚ùå ERRO: Nenhum arquivo preds_T=*.parquet encontrado!\")\n",
    "    print(\"\\nVerificando estrutura de diret√≥rios...\")\n",
    "    if data_dir.exists():\n",
    "        all_files = list(data_dir.glob('*'))\n",
    "        print(f\"\\nArquivos em {data_dir}:\")\n",
    "        for f in all_files[:10]:  # Primeiros 10\n",
    "            print(f\"  - {f.name}\")\n",
    "\n",
    "# Buscar metadados opcionais\n",
    "meta_file = data_dir / 'meta_pred.json'\n",
    "qc_file = data_dir / 'qc_oos.json'\n",
    "\n",
    "print(f\"\\nüìã Metadados:\")\n",
    "print(f\"  meta_pred.json: {'‚úì Encontrado' if meta_file.exists() else '‚úó N√£o encontrado'}\")\n",
    "print(f\"  qc_oos.json:    {'‚úì Encontrado' if qc_file.exists() else '‚úó N√£o encontrado'}\")\n",
    "\n",
    "print(\"\\n‚úÖ Descoberta conclu√≠da\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafefaba",
   "metadata": {},
   "source": [
    "### 2.2 Carregar e Concatenar Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "deedea04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Carregado preds_T=42.parquet: 1 linhas\n",
      "\n",
      "üìä Dataset concatenado: 1 linhas, 12 colunas\n",
      "\n",
      "üìã Colunas dispon√≠veis:\n",
      "  S0, T, h_days, p_25, p_50, p_75, p_med, q25, q50, q75, rvhat_ann, ts0\n",
      "\n",
      "üîç Primeiras linhas:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts0</th>\n",
       "      <th>T</th>\n",
       "      <th>h_days</th>\n",
       "      <th>S0</th>\n",
       "      <th>rvhat_ann</th>\n",
       "      <th>q25</th>\n",
       "      <th>p_25</th>\n",
       "      <th>q50</th>\n",
       "      <th>p_50</th>\n",
       "      <th>q75</th>\n",
       "      <th>p_75</th>\n",
       "      <th>p_med</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-10-02 00:00:00+00:00</td>\n",
       "      <td>42</td>\n",
       "      <td>7.0</td>\n",
       "      <td>118822.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.016067</td>\n",
       "      <td>116928.199661</td>\n",
       "      <td>0.010727</td>\n",
       "      <td>120103.593414</td>\n",
       "      <td>0.039374</td>\n",
       "      <td>123593.87164</td>\n",
       "      <td>120103.593414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ts0   T  h_days        S0  rvhat_ann       q25  \\\n",
       "0 2025-10-02 00:00:00+00:00  42     7.0  118822.1        NaN -0.016067   \n",
       "\n",
       "            p_25       q50           p_50       q75          p_75  \\\n",
       "0  116928.199661  0.010727  120103.593414  0.039374  123593.87164   \n",
       "\n",
       "           p_med  \n",
       "0  120103.593414  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Dados carregados\n"
     ]
    }
   ],
   "source": [
    "# Carregar todos os arquivos de predi√ß√£o\n",
    "if not pred_files:\n",
    "    raise FileNotFoundError(\"‚ùå Nenhum arquivo de predi√ß√£o encontrado. Verifique o diret√≥rio de dados.\")\n",
    "\n",
    "dfs = []\n",
    "for f in pred_files:\n",
    "    try:\n",
    "        df_temp = pd.read_parquet(f)\n",
    "        dfs.append(df_temp)\n",
    "        print(f\"‚úì Carregado {f.name}: {len(df_temp):,} linhas\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚úó Erro ao carregar {f.name}: {e}\")\n",
    "\n",
    "# Concatenar\n",
    "if dfs:\n",
    "    df_raw = pd.concat(dfs, ignore_index=True)\n",
    "    print(f\"\\nüìä Dataset concatenado: {len(df_raw):,} linhas, {len(df_raw.columns)} colunas\")\n",
    "else:\n",
    "    raise ValueError(\"‚ùå Nenhum arquivo foi carregado com sucesso\")\n",
    "\n",
    "# Exibir colunas dispon√≠veis\n",
    "print(f\"\\nüìã Colunas dispon√≠veis:\")\n",
    "print(f\"  {', '.join(sorted(df_raw.columns))}\")\n",
    "\n",
    "# Amostra dos dados\n",
    "print(f\"\\nüîç Primeiras linhas:\")\n",
    "display(df_raw.head())\n",
    "\n",
    "print(\"\\n‚úÖ Dados carregados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2406ff6b",
   "metadata": {},
   "source": [
    "## 3. Data Validation & Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f5c553",
   "metadata": {},
   "source": [
    "### 3.1 Valida√ß√µes B√°sicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d273f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Executando valida√ß√µes...\n",
      "\n",
      "‚úì Coluna 'ts0' convertida para UTC\n",
      "\n",
      "üìä Horizontes encontrados: [np.int64(42)]\n",
      "‚úì Dataset filtrado: 1 linhas com T v√°lido\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "‚ùå Colunas obrigat√≥rias ausentes: ['q05', 'q95']",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     26\u001b[39m missing_cols = [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m required_cols \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m df_raw.columns]\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m missing_cols:\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚ùå Colunas obrigat√≥rias ausentes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_cols\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     31\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m‚úì Todas as colunas obrigat√≥rias presentes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequired_cols\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: ‚ùå Colunas obrigat√≥rias ausentes: ['q05', 'q95']"
     ]
    }
   ],
   "source": [
    "print(\"üîç Executando valida√ß√µes...\\n\")\n",
    "\n",
    "# 1. Converter ts0 para UTC\n",
    "if 'ts0' in df_raw.columns:\n",
    "    df_raw['ts0'] = pd.to_datetime(df_raw['ts0'], utc=True)\n",
    "    print(f\"‚úì Coluna 'ts0' convertida para UTC\")\n",
    "else:\n",
    "    raise ValueError(\"‚ùå Coluna 'ts0' n√£o encontrada\")\n",
    "\n",
    "# 2. Filtrar horizontes v√°lidos\n",
    "if 'T' in df_raw.columns:\n",
    "    horizons_found = df_raw['T'].unique()\n",
    "    print(f\"\\nüìä Horizontes encontrados: {sorted(horizons_found)}\")\n",
    "    \n",
    "    invalid_T = [t for t in horizons_found if t not in CONFIG['horizons']]\n",
    "    if invalid_T:\n",
    "        print(f\"‚ö†Ô∏è  Horizontes inv√°lidos (ser√£o ignorados): {invalid_T}\")\n",
    "        df_raw = df_raw[df_raw['T'].isin(CONFIG['horizons'])].copy()\n",
    "    \n",
    "    print(f\"‚úì Dataset filtrado: {len(df_raw):,} linhas com T v√°lido\")\n",
    "else:\n",
    "    raise ValueError(\"‚ùå Coluna 'T' n√£o encontrada\")\n",
    "\n",
    "# 3. Verificar campos obrigat√≥rios\n",
    "# Nota: Os arquivos t√™m q25, q50, q75 (n√£o q05/q95)\n",
    "required_cols = ['ts0', 'T', 'S0', 'q25', 'q50', 'q75']\n",
    "optional_cols = ['p_25', 'p_50', 'p_75', 'p_med', 'rvhat_ann', 'h_days']\n",
    "\n",
    "missing_cols = [col for col in required_cols if col not in df_raw.columns]\n",
    "\n",
    "if missing_cols:\n",
    "    raise ValueError(f\"‚ùå Colunas obrigat√≥rias ausentes: {missing_cols}\")\n",
    "else:\n",
    "    print(f\"\\n‚úì Todas as colunas obrigat√≥rias presentes: {required_cols}\")\n",
    "\n",
    "# Verificar colunas opcionais dispon√≠veis\n",
    "available_optional = [col for col in optional_cols if col in df_raw.columns]\n",
    "print(f\"‚úì Colunas opcionais dispon√≠veis: {available_optional}\")\n",
    "\n",
    "# 4. Verificar monotonicidade dos quantis (q25 <= q50 <= q75)\n",
    "monotone_check = (\n",
    "    (df_raw['q25'] <= df_raw['q50']) &\n",
    "    (df_raw['q50'] <= df_raw['q75'])\n",
    ")\n",
    "\n",
    "n_violations = (~monotone_check).sum()\n",
    "pct_violations = 100 * n_violations / len(df_raw)\n",
    "\n",
    "print(f\"\\nüîç Monotonicidade dos quantis (q25 ‚â§ q50 ‚â§ q75):\")\n",
    "print(f\"  Total de linhas: {len(df_raw):,}\")\n",
    "print(f\"  Viola√ß√µes: {n_violations:,} ({pct_violations:.2f}%)\")\n",
    "\n",
    "if pct_violations > 1.0:\n",
    "    print(f\"  ‚ö†Ô∏è  ATEN√á√ÉO: {pct_violations:.2f}% de viola√ß√µes (limite: 1%)\")\n",
    "else:\n",
    "    print(f\"  ‚úì Monotonicidade OK ({pct_violations:.4f}% viola√ß√µes)\")\n",
    "\n",
    "# 5. Verificar rec√™ncia\n",
    "latest_ts = df_raw['ts0'].max()\n",
    "now = pd.Timestamp.now(tz='UTC')\n",
    "days_since_last = (now - latest_ts).days\n",
    "\n",
    "print(f\"\\nüìÖ Rec√™ncia dos dados:\")\n",
    "print(f\"  √öltima previs√£o: {latest_ts}\")\n",
    "print(f\"  Dias desde √∫ltima: {days_since_last}\")\n",
    "print(f\"  Limite configurado: {CONFIG['recency_max_days']} dias\")\n",
    "\n",
    "if days_since_last > CONFIG['recency_max_days']:\n",
    "    print(f\"  ‚ö†Ô∏è  ATEN√á√ÉO: Dados podem estar desatualizados\")\n",
    "else:\n",
    "    print(f\"  ‚úì Dados recentes\")\n",
    "\n",
    "# 6. Verificar NaNs em colunas cr√≠ticas\n",
    "print(f\"\\nüîç NaNs em colunas cr√≠ticas:\")\n",
    "for col in required_cols:\n",
    "    n_nans = df_raw[col].isna().sum()\n",
    "    if n_nans > 0:\n",
    "        print(f\"  ‚ö†Ô∏è  {col}: {n_nans:,} NaNs ({100*n_nans/len(df_raw):.2f}%)\")\n",
    "    else:\n",
    "        print(f\"  ‚úì {col}: sem NaNs\")\n",
    "\n",
    "print(\"\\n‚úÖ Valida√ß√µes conclu√≠das\")\n",
    "print(f\"\\nüìù Nota: Dataset cont√©m quantis q25, q50, q75 (n√£o q05/q95)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ffda94",
   "metadata": {},
   "source": [
    "### 3.2 Informa√ß√µes do Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb912363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumo estat√≠stico\n",
    "print(\"üìä Resumo do Dataset\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total de linhas: {len(df_raw):,}\")\n",
    "print(f\"Total de colunas: {len(df_raw.columns)}\")\n",
    "print(f\"\\nPer√≠odo dos dados:\")\n",
    "print(f\"  In√≠cio: {df_raw['ts0'].min()}\")\n",
    "print(f\"  Fim:    {df_raw['ts0'].max()}\")\n",
    "print(f\"  Dias:   {(df_raw['ts0'].max() - df_raw['ts0'].min()).days}\")\n",
    "\n",
    "print(f\"\\nüìà Distribui√ß√£o por horizonte T:\")\n",
    "for T in sorted(df_raw['T'].unique()):\n",
    "    n = (df_raw['T'] == T).sum()\n",
    "    pct = 100 * n / len(df_raw)\n",
    "    print(f\"  T={T}h: {n:6,} linhas ({pct:5.2f}%)\")\n",
    "\n",
    "print(f\"\\nüí∞ Estat√≠sticas de S0 (pre√ßo spot):\")\n",
    "print(f\"  Min:    ${df_raw['S0'].min():,.2f}\")\n",
    "print(f\"  M√©dia:  ${df_raw['S0'].mean():,.2f}\")\n",
    "print(f\"  Mediana:${df_raw['S0'].median():,.2f}\")\n",
    "print(f\"  Max:    ${df_raw['S0'].max():,.2f}\")\n",
    "\n",
    "# Estat√≠sticas dos quantis dispon√≠veis\n",
    "print(f\"\\nüìä Estat√≠sticas dos Quantis (valores relativos):\")\n",
    "quantile_cols = ['q25', 'q50', 'q75']\n",
    "print(df_raw[quantile_cols].describe())\n",
    "\n",
    "# Se tiver pre√ßos absolutos, mostrar tamb√©m\n",
    "if 'p_25' in df_raw.columns:\n",
    "    print(f\"\\nüíµ Estat√≠sticas de Pre√ßos Absolutos (USD):\")\n",
    "    price_cols = ['p_25', 'p_50', 'p_75']\n",
    "    available_price_cols = [c for c in price_cols if c in df_raw.columns]\n",
    "    if available_price_cols:\n",
    "        print(df_raw[available_price_cols].describe())\n",
    "\n",
    "# Volatilidade realizada se dispon√≠vel\n",
    "if 'rvhat_ann' in df_raw.columns:\n",
    "    print(f\"\\nüìâ Estat√≠sticas de Volatilidade Realizada Anualizada:\")\n",
    "    print(f\"  Min:    {df_raw['rvhat_ann'].min():.4f}\")\n",
    "    print(f\"  M√©dia:  {df_raw['rvhat_ann'].mean():.4f}\")\n",
    "    print(f\"  Mediana:{df_raw['rvhat_ann'].median():.4f}\")\n",
    "    print(f\"  Max:    {df_raw['rvhat_ann'].max():.4f}\")\n",
    "\n",
    "print(\"\\n‚úÖ Informa√ß√µes do dataset exibidas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8318a616",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d16155",
   "metadata": {},
   "source": [
    "### 4.1 Criar Bandas Absolutas e Quantis Adicionais\n",
    "\n",
    "Como os dados cont√™m apenas q25, q50, q75, vamos:\n",
    "1. Criar bandas de pre√ßo absolutas (p = S0 √ó q) se necess√°rio\n",
    "2. Estimar q05 e q95 usando a assimetria dos quantis existentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d636a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar c√≥pia para trabalhar\n",
    "df = df_raw.copy()\n",
    "\n",
    "print(\"üîß Enriquecendo dataset com features derivadas...\\n\")\n",
    "\n",
    "# 1. Garantir que temos pre√ßos absolutos p_25, p_50, p_75\n",
    "if 'p_25' not in df.columns:\n",
    "    df['p_25'] = df['S0'] * df['q25']\n",
    "    print(\"‚úì Criado p_25 = S0 √ó q25\")\n",
    "    \n",
    "if 'p_50' not in df.columns:\n",
    "    df['p_50'] = df['S0'] * df['q50']\n",
    "    print(\"‚úì Criado p_50 = S0 √ó q50\")\n",
    "    \n",
    "if 'p_75' not in df.columns:\n",
    "    df['p_75'] = df['S0'] * df['q75']\n",
    "    print(\"‚úì Criado p_75 = S0 √ó q75\")\n",
    "\n",
    "# 2. Estimar q05 e q95 usando extrapola√ß√£o sim√©trica\n",
    "# Assuma distribui√ß√£o sim√©trica em torno de q50 (pode ser ajustado)\n",
    "# q05 ‚âà q50 - k*(q50-q25), onde k √© fator de extrapola√ß√£o\n",
    "# q95 ‚âà q50 + k*(q75-q50)\n",
    "\n",
    "# Usar raz√£o baseada na dist√¢ncia normal padr√£o\n",
    "# Dist√¢ncia q25‚Üíq50: 0.25 da distribui√ß√£o (z ‚âà -0.674)\n",
    "# Dist√¢ncia q05‚Üíq50: 0.45 da distribui√ß√£o (z ‚âà -1.645)\n",
    "# Ratio: 1.645/0.674 ‚âà 2.44\n",
    "\n",
    "k_lower = 2.44  # extrapola√ß√£o para q05\n",
    "k_upper = 2.44  # extrapola√ß√£o para q95\n",
    "\n",
    "df['q05'] = df['q50'] - k_lower * (df['q50'] - df['q25'])\n",
    "df['q95'] = df['q50'] + k_upper * (df['q75'] - df['q50'])\n",
    "\n",
    "# Criar pre√ßos absolutos correspondentes\n",
    "df['p_05'] = df['S0'] * df['q05']\n",
    "df['p_95'] = df['S0'] * df['q95']\n",
    "\n",
    "print(f\"‚úì Estimado q05 e q95 (extrapola√ß√£o k={k_lower:.2f})\")\n",
    "print(f\"‚úì Criado p_05 e p_95\")\n",
    "\n",
    "# 3. Verificar sanidade dos quantis estimados\n",
    "print(f\"\\nüîç Valida√ß√£o dos quantis estimados:\")\n",
    "monotone_full = (\n",
    "    (df['q05'] <= df['q25']) &\n",
    "    (df['q25'] <= df['q50']) &\n",
    "    (df['q50'] <= df['q75']) &\n",
    "    (df['q75'] <= df['q95'])\n",
    ")\n",
    "n_ok = monotone_full.sum()\n",
    "pct_ok = 100 * n_ok / len(df)\n",
    "print(f\"  Monotonicidade q05‚â§q25‚â§q50‚â§q75‚â§q95: {pct_ok:.2f}% OK\")\n",
    "\n",
    "if pct_ok < 95:\n",
    "    print(f\"  ‚ö†Ô∏è  Ajustando quantis que violam monotonicidade...\")\n",
    "    # For√ßar monotonicidade\n",
    "    df.loc[df['q05'] > df['q25'], 'q05'] = df.loc[df['q05'] > df['q25'], 'q25'] * 0.99\n",
    "    df.loc[df['q95'] < df['q75'], 'q95'] = df.loc[df['q95'] < df['q75'], 'q75'] * 1.01\n",
    "    df['p_05'] = df['S0'] * df['q05']\n",
    "    df['p_95'] = df['S0'] * df['q95']\n",
    "    print(f\"  ‚úì Quantis ajustados para garantir monotonicidade\")\n",
    "\n",
    "print(f\"\\n‚úÖ Dataset enriquecido: {len(df.columns)} colunas\")\n",
    "print(f\"üìã Quantis dispon√≠veis: q05, q25, q50, q75, q95\")\n",
    "print(f\"üí∞ Pre√ßos dispon√≠veis: p_05, p_25, p_50, p_75, p_95\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
