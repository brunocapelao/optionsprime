"""
Optimized Training Pipeline Module
=================================

Intelligent training pipeline with Optuna, parameter reuse, and performance optimizations.
"""

import argparse
import json
import time
from pathlib import Path
from typing import Dict, Any, List, Optional
import warnings
from functools import partial

import numpy as np
import pandas as pd
import lightgbm as lgb
import joblib
from tqdm import tqdm
import optuna
from optuna.pruners import HyperbandPruner

from .utils import (
    set_seeds, load_features, load_cpcv, write_json_atomic, 
    save_joblib_atomic, get_env_versions, compute_file_hash,
    remove_constant_columns, remove_high_nan_columns, 
    remove_collinear_features, apply_time_decay_weights
)
from .cv import (
    build_xy_datasets, get_cpcv_folds, evaluate_cpcv, 
    rearrange_quantiles, check_quantile_crossing_rate,
    compute_interval_score
)
from .conformal import fit_conformal, nonconformity_errors
from .qc import run_comprehensive_qc, apply_isotonic_width_correction


def smart_hyperparameter_search(
    dataset: Dict[str, Any],
    folds: List[Dict[str, Any]],
    model_config: Dict[str, Any],
    reuse_params: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """
    Smart hyperparameter search with Optuna, pruning, and parameter reuse.
    
    Optimizations:
    1. Bayesian optimization with Hyperband pruning
    2. Reduced tau set for tuning (0.5, 0.95 only)
    3. Temporal subsampling (2-3 folds for tuning)
    4. Parameter reuse between similar T horizons
    5. Early pruning after first fold evaluation
    """
    T = dataset['T_horizon']
    print(f"üéØ Smart hyperparameter search for T={T}")
    
    # Strategy: full tuning vs light tuning
    if reuse_params:
        print(f"üìã Reusing params from similar T, light tuning (20 trials)")
        n_trials = 20
    else:
        print(f"üîç Full tuning for T={T} (100 trials)")
        n_trials = 100
    
    # Optimization 2: Reduced tau set for tuning
    tuning_taus = [0.5, 0.95]
    print(f"‚ö° Tuning with reduced tau set: {tuning_taus}")
    
    # Optimization 3: Temporal subsampling for tuning
    tuning_folds = folds[:3]  # Use only first 3 folds
    print(f"üìä Using {len(tuning_folds)}/{len(folds)} folds for tuning")
    
    def objective(trial, dataset, folds, base_params):
        """Optuna objective with early pruning."""
        
        # Define parameter search space
        if base_params:
            # Light tuning around base parameters
            params = {
                'learning_rate': trial.suggest_float('learning_rate', 
                    max(0.01, base_params.get('learning_rate', 0.1) * 0.5),
                    min(0.3, base_params.get('learning_rate', 0.1) * 1.5), log=True),
                'num_leaves': trial.suggest_int('num_leaves',
                    max(10, int(base_params.get('num_leaves', 31) * 0.7)),
                    min(300, int(base_params.get('num_leaves', 31) * 1.3))),
                'max_depth': base_params.get('max_depth', -1),
                'min_data_in_leaf': base_params.get('min_data_in_leaf', 20),
                'feature_fraction': trial.suggest_float('feature_fraction',
                    max(0.4, base_params.get('feature_fraction', 0.8) - 0.2),
                    min(1.0, base_params.get('feature_fraction', 0.8) + 0.2)),
                'bagging_fraction': base_params.get('bagging_fraction', 0.8),
                'lambda_l1': base_params.get('lambda_l1', 0.0),
                'lambda_l2': base_params.get('lambda_l2', 0.0)
            }
        else:
            # Full parameter search
            params = {
                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),
                'num_leaves': trial.suggest_int('num_leaves', 10, 300),
                'max_depth': trial.suggest_int('max_depth', 3, 15),
                'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 100),
                'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0),
                'bagging_fraction': trial.suggest_float('bagging_fraction', 0.4, 1.0),
                'lambda_l1': trial.suggest_float('lambda_l1', 0.0, 10.0),
                'lambda_l2': trial.suggest_float('lambda_l2', 0.0, 10.0)
            }
        
        fold_scores = []
        
        # Optimization 5: Early pruning after first fold
        for fold_idx, fold in enumerate(folds):
            if len(fold['train_indices']) == 0 or len(fold['val_indices']) == 0:
                continue
            
            # Prepare fold data
            X_train = dataset['X'].iloc[fold['train_indices']]
            y_train = dataset['y'].iloc[fold['train_indices']]
            X_val = dataset['X'].iloc[fold['val_indices']]
            y_val = dataset['y'].iloc[fold['val_indices']].values
            
            # Train models for key quantiles only
            fold_predictions = {}
            
            for tau in tuning_taus:
                lgb_params = {
                    'objective': 'quantile',
                    'alpha': tau,
                    'metric': 'quantile',
                    'boosting_type': 'gbdt',
                    'verbose': -1,
                    'seed': 17,
                    'num_threads': 4,  # Controlled threading to avoid over-subscription
                    **params
                }
                
                # Prepare datasets
                train_data = lgb.Dataset(X_train, label=y_train)
                val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)
                
                # Train model
                model = lgb.train(
                    lgb_params,
                    train_data,
                    num_boost_round=1000,
                    valid_sets=[val_data],
                    callbacks=[
                        lgb.early_stopping(50, verbose=False),
                        lgb.log_evaluation(0)
                    ]
                )
                
                pred = model.predict(X_val)
                fold_predictions[tau] = pred
            
            # Compute interval score for pruning decision
            if 0.5 in fold_predictions and 0.95 in fold_predictions:
                interval_score = compute_interval_score(
                    y_val, fold_predictions[0.5], fold_predictions[0.95], alpha=0.1
                )
                fold_scores.append(interval_score)
                
                # Report to pruner after first fold
                if fold_idx == 0:
                    trial.report(interval_score, fold_idx)
                    if trial.should_prune():
                        raise optuna.TrialPruned()
        
        return np.mean(fold_scores) if fold_scores else float('inf')
    
    # Create study with Hyperband pruner
    pruner = HyperbandPruner(min_resource=1, max_resource=len(tuning_folds))
    study = optuna.create_study(direction='minimize', pruner=pruner)
    
    # Run optimization with progress bar
    objective_func = partial(objective, dataset=dataset, folds=tuning_folds, base_params=reuse_params)
    
    with tqdm(total=n_trials, desc=f"T={T} Optuna", unit="trial") as pbar:
        def callback(study, trial):
            pbar.update(1)
            pbar.set_postfix({"best": f"{study.best_value:.4f}", "trials": len(study.trials)})
        
        study.optimize(objective_func, n_trials=n_trials, callbacks=[callback])
    
    best_params = study.best_params
    best_score = study.best_value
    
    print(f"‚úÖ Best interval score: {best_score:.6f}")
    print(f"üìã Best params: {best_params}")
    
    return {
        'best_params': best_params,
        'best_score': best_score,
        'study': study,
        'n_trials': len(study.trials),
        'n_pruned': len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED])
    }


def train_quantile_models_optimized(
    dataset: Dict[str, Any],
    folds: List[Dict[str, Any]],
    best_params: Dict[str, Any],
    taus: List[float],
    weights_config: Optional[Dict[str, Any]] = None
) -> Dict[float, Any]:
    """
    Optimized quantile model training with controlled threading.
    """
    T = dataset['T_horizon']
    print(f"üöÄ Training optimized models for T={T}")
    
    models = {}
    
    # Combine all training data
    all_train_indices = []
    for fold in folds:
        all_train_indices.extend(fold['train_indices'])
    all_train_indices = sorted(list(set(all_train_indices)))
    
    if len(all_train_indices) == 0:
        raise ValueError("No training indices found")
    
    X_train = dataset['X'].iloc[all_train_indices]
    y_train = dataset['y'].iloc[all_train_indices]
    
    # Apply time-decay weights if configured
    sample_weights = None
    if weights_config and weights_config.get('time_decay_lambda'):
        train_timestamps = dataset['timestamps'][all_train_indices]
        sample_weights = apply_time_decay_weights(
            train_timestamps, 
            weights_config['time_decay_lambda']
        )
        print(f"‚öñÔ∏è  Applied time-decay weights (Œª={weights_config['time_decay_lambda']})")
    
    # Train models with progress bar
    tau_pbar = tqdm(taus, desc=f"T={T} Models", unit="œÑ")
    
    for tau in tau_pbar:
        tau_pbar.set_description(f"T={T} œÑ={tau}")
        
        lgb_params = {
            'objective': 'quantile',
            'alpha': tau,
            'metric': 'quantile',
            'boosting_type': 'gbdt',
            'verbose': -1,
            'seed': 17,
            'num_threads': 4,  # Controlled threading
            **best_params
        }
        
        # Prepare training data
        train_data = lgb.Dataset(X_train, label=y_train, weight=sample_weights)
        
        # Train final model (fixed rounds, no early stopping)
        model = lgb.train(
            lgb_params,
            train_data,
            num_boost_round=300,  # Reduced from 500 for speed
            callbacks=[lgb.log_evaluation(0)]
        )
        
        models[tau] = model
    
    tau_pbar.close()
    print(f"‚úÖ Trained {len(models)} quantile models for T={T}")
    return models


def run_optimized_training_pipeline(config: Dict[str, Any]) -> None:
    """
    Run optimized training pipeline with intelligent hyperparameter reuse.
    
    Key optimizations:
    1. Smart parameter reuse between T horizons
    2. Optuna with pruning for hyperparameter search
    3. Reduced tau set for tuning
    4. Temporal subsampling for CV
    5. Controlled threading to avoid over-subscription
    """
    print("üöÄ Starting Optimized 02a Training Pipeline")
    print("=" * 50)
    
    # Set seeds
    set_seeds(17)
    
    # Load configuration
    targets_T = config['targets_T']
    taus = config['taus']
    output_dir = Path(config['output']['dir'])
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # Load data
    print("üíæ Loading data...")
    features_df = load_features(config['data']['features_path'])
    cv_splits = load_cpcv(config['data']['cv_splits_path'])
    
    print(f"üìä Features shape: {features_df.shape}")
    print(f"üéØ Targets: {targets_T}")
    print(f"üìè Quantiles: {taus}")
    
    # Prepare datasets
    datasets = prepare_datasets(features_df, targets_T, config['data'])
    
    # Training results storage
    all_models = {}
    all_cv_metrics = {}
    all_calibrators = {}
    
    # Parameter reuse strategy
    shared_params = {}
    full_tuning_T = [42, 60]  # Do full tuning for boundary cases
    reuse_mapping = {48: 42, 54: 60}  # T=48 reuses T=42, T=54 reuses T=60
    
    start_time = time.time()
    
    # Main training loop with progress bar
    target_pbar = tqdm(targets_T, desc="üéØ Training", unit="T")
    
    for T in target_pbar:
        target_pbar.set_description(f"üéØ Training T={T}")
        print(f"\n{'='*20} Training T={T} {'='*20}")
        
        dataset = datasets[T]
        
        # Get CV folds
        folds = get_cpcv_folds(
            cv_splits, 
            dataset, 
            embargo_bars=config['cpcv']['embargo_bars_4h']
        )
        
        print(f"üìÇ Generated {len(folds)} CPCV folds")
        
        if len(folds) == 0:
            print(f"‚ö†Ô∏è  No valid folds for T={T}, skipping")
            continue
        
        # Smart hyperparameter search
        reuse_params = None
        if T not in full_tuning_T and T in reuse_mapping:
            source_T = reuse_mapping[T]
            if source_T in shared_params:
                reuse_params = shared_params[source_T]['best_params']
                print(f"‚ôªÔ∏è  Reusing hyperparameters from T={source_T}")
        
        search_result = smart_hyperparameter_search(
            dataset, folds, config['model'], reuse_params
        )
        
        # Store parameters for reuse
        shared_params[T] = search_result
        
        # Train final models
        models_T = train_quantile_models_optimized(
            dataset, folds, search_result['best_params'], 
            taus, config.get('weights')
        )
        
        # Quick CV evaluation
        print("üìà Evaluating with CPCV...")
        cv_metrics = evaluate_cpcv(models_T, dataset, folds, taus)
        cv_metrics['hyperparameter_search'] = {
            'best_score': search_result['best_score'],
            'n_trials': search_result['n_trials'],
            'n_pruned': search_result['n_pruned']
        }
        
        # Store results
        all_models[T] = models_T
        all_cv_metrics[T] = cv_metrics
        
        target_pbar.set_postfix({
            "completed": f"{len(all_models)}/{len(targets_T)}",
            "score": f"{search_result['best_score']:.3f}"
        })
    
    target_pbar.close()
    
    # Final pipeline steps
    print("\nüîç Running quality control...")
    # ... QC implementation
    
    print("\nüíæ Saving artifacts...")
    # ... Save results
    
    execution_time = time.time() - start_time
    print(f"\n‚úÖ Pipeline completed in {execution_time:.1f}s")
    print(f"üèÜ Trained models for {len(all_models)} horizons")
    
    return {
        'models': all_models,
        'cv_metrics': all_cv_metrics,
        'execution_time': execution_time,
        'shared_params': shared_params
    }


# Import prepare_datasets from original module
def prepare_datasets(features_df: pd.DataFrame, targets_T: List[int], data_config: Dict[str, Any]):
    """Placeholder - import from original train.py"""
    from .train import prepare_datasets
    return prepare_datasets(features_df, targets_T, data_config)


def main():
    """CLI entry point for optimized training."""
    parser = argparse.ArgumentParser(description="Optimized 02a Training Pipeline")
    parser.add_argument("--config", required=True, help="Configuration YAML file")
    parser.add_argument("--features", help="Override features path")
    parser.add_argument("--cv-splits", help="Override CV splits path")
    parser.add_argument("--out-dir", help="Override output directory")
    
    args = parser.parse_args()
    
    # Load config
    with open(args.config, 'r') as f:
        import yaml
        config = yaml.safe_load(f)
    
    # Apply overrides
    if args.features:
        config['data']['features_path'] = args.features
    if args.cv_splits:
        config['data']['cv_splits_path'] = args.cv_splits
    if args.out_dir:
        config['output']['dir'] = args.out_dir
    
    try:
        result = run_optimized_training_pipeline(config)
        print("üéâ Training completed successfully!")
        exit(0)
    except Exception as e:
        print(f"‚ùå Pipeline failed: {e}")
        import traceback
        traceback.print_exc()
        exit(1)


if __name__ == "__main__":
    main()